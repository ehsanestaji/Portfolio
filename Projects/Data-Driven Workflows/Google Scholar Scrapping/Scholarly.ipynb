{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f23539-3e51-427b-812f-0740527f14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from scholarly import scholarly\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "\n",
    "def Lexicon_List_Wrapper():\n",
    "    f = open(\"lexicon.txt\", \"r\")\n",
    "    lex_list = []\n",
    "    for lines in f.readlines():\n",
    "        if len(lines) > 0:\n",
    "            title = re.findall(r'\\\"(.+?)\\\"', lines)\n",
    "            lex_list.append(title[0])\n",
    "    return lex_list\n",
    "\n",
    "\n",
    "\n",
    "def PaperGrabber(keyword,depth =15): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*30)) #from 5 to 30 seconds\n",
    "    search_query = scholarly.search_pubs(keyword)                                        \n",
    "    data = []\n",
    "    for i in range(depth):\n",
    "        time.sleep((3)*np.random.random()+5) #from 5 to 30 seconds\n",
    "        bibitem = next(search_query)\n",
    "        container_type = bibitem['container_type'] if ('container_type' in bibitem.keys()) else None\n",
    "        title = bibitem['bib']['title']\n",
    "        author = bibitem['bib']['author']\n",
    "        pub_year = bibitem['bib']['pub_year']\n",
    "        venue = bibitem['bib']['venue']\n",
    "        abstract = bibitem['bib']['abstract']\n",
    "        #pub_url = next(search_query)['pub_url']\n",
    "        #if  ('pub_url' in next(search_query).keys()):\n",
    "           # pub_url = next(search_query)['pub_url'] \n",
    "        #else:\n",
    "        #    pub_url ='None'\n",
    "        author_id = bibitem['author_id']\n",
    "        num_citations = bibitem['num_citations']\n",
    "        data.append([container_type,title,author,  pub_year,venue,abstract,author_id,num_citations])\n",
    "    df = pd.DataFrame(data, columns = ['container_type', 'title','author','pub_year','venue','abstract','author_id','num_citations']) \n",
    "    return df    \n",
    "\n",
    "\n",
    "def FinalCollector(_from,_to):\n",
    "    dff=pd.DataFrame()\n",
    "    for word in tqdm(Lexicon_List_Wrapper()[_from:_to]):\n",
    "        dff = dff.append(PaperGrabber(word), ignore_index= True)\n",
    "    filename = \"data_from_\"+str(_from)+\"_to_\"+str(_to)+\".csv\"\n",
    "    dff.to_csv(filename)\n",
    "    return dff\n",
    "\n",
    "\n",
    "import os\n",
    "import glob \n",
    "\n",
    "def FileMarger():\n",
    "    files = os.path.join(\"data_from*.csv\")\n",
    "    files = glob.glob(files)\n",
    "    df = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "    df.drop('Unnamed: 0', axis = 1, inplace= True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5293f8ac-ead4-43aa-bdc5-ef92f3f7dd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:51<01:51, 111.84s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:49<00:00, 114.84s/it]\u001b[A\n",
      " 10%|█         | 1/10 [04:25<39:51, 265.72s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:08<02:08, 128.93s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:17<00:00, 128.66s/it]\u001b[A\n",
      " 20%|██        | 2/10 [09:03<36:20, 272.57s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:09<02:09, 129.19s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:10<00:00, 125.38s/it]\u001b[A\n",
      " 30%|███       | 3/10 [14:05<33:24, 286.41s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:44<01:44, 104.54s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:48<00:00, 114.16s/it]\u001b[A\n",
      " 40%|████      | 4/10 [18:53<28:40, 286.78s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:46<01:46, 106.71s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:45<00:00, 112.66s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [23:22<23:22, 280.49s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:01<02:01, 121.53s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:03<00:00, 121.51s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [27:52<18:27, 276.94s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:45<01:45, 105.63s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:50<00:00, 115.44s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [32:02<13:24, 268.10s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:37<01:37, 97.44s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:40<00:00, 110.44s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [36:42<09:03, 271.85s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:06<02:06, 126.18s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:09<00:00, 124.61s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [41:46<04:41, 281.98s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:06<02:06, 126.72s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:15<00:00, 127.65s/it]\u001b[A\n",
      "100%|██████████| 10/10 [46:36<00:00, 279.60s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(150,170,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*60)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f49f134-3f73-4eef-892b-8e724e8824e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:58<01:58, 118.79s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:58<00:00, 119.41s/it]\u001b[A\n",
      " 10%|█         | 1/10 [04:28<40:19, 268.88s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:58<01:58, 118.36s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:48<00:00, 114.43s/it]\u001b[A\n",
      " 20%|██        | 2/10 [09:02<36:14, 271.82s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:54<01:54, 114.94s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:02<00:00, 121.13s/it]\u001b[A\n",
      " 30%|███       | 3/10 [13:59<33:00, 282.99s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:01<02:01, 121.19s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:15<00:00, 127.58s/it]\u001b[A\n",
      " 40%|████      | 4/10 [18:46<28:27, 284.64s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:52<01:52, 112.18s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:52<00:00, 116.17s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [23:14<23:13, 278.76s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:58<01:58, 118.38s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:57<00:00, 118.75s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [28:11<18:59, 284.80s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:01<02:01, 121.18s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:58<00:00, 119.30s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [33:01<14:20, 286.69s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:52<01:52, 112.66s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:00<00:00, 120.40s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [37:52<09:36, 288.00s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:04<02:04, 124.63s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:11<00:00, 125.62s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [42:32<04:45, 285.58s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:57<01:57, 117.88s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:00<00:00, 120.47s/it]\u001b[A\n",
      "100%|██████████| 10/10 [46:55<00:00, 281.57s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(170,190,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*60)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0820667f-a940-4349-accf-6b50ef972541",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:48<01:48, 108.11s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:52<00:00, 116.16s/it]\u001b[A\n",
      " 10%|█         | 1/10 [04:24<39:39, 264.34s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:04<02:04, 124.77s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:54<00:00, 117.13s/it]\u001b[A\n",
      " 20%|██        | 2/10 [09:17<37:30, 281.35s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:54<01:54, 114.94s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:45<00:00, 112.74s/it]\u001b[A\n",
      " 30%|███       | 3/10 [13:10<30:13, 259.04s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:09<02:09, 129.45s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:15<00:00, 127.74s/it]\u001b[A\n",
      " 40%|████      | 4/10 [18:21<27:58, 279.75s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:02<02:02, 122.76s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:58<00:00, 119.33s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [22:22<22:08, 265.66s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:13<02:13, 133.07s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:20<00:00, 130.38s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [27:36<18:48, 282.01s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:12<02:12, 132.01s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:06<00:00, 123.10s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [32:00<13:48, 276.20s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:01<02:01, 121.09s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:10<00:00, 125.49s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [37:09<09:33, 286.64s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:54<01:54, 114.46s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:00<00:00, 120.16s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [41:34<04:39, 279.98s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:05<02:05, 125.75s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:55<00:00, 117.55s/it]\u001b[A\n",
      "100%|██████████| 10/10 [45:57<00:00, 275.77s/it]\n"
     ]
    }
   ],
   "source": [
    "time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*60)) \n",
    "\n",
    "\n",
    "for i in tqdm(range(190,210,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*60)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea6cd1eb-6576-4645-a919-fe0d2cb46a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:58<01:58, 118.50s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:13<00:00, 126.73s/it]\u001b[A\n",
      " 10%|█         | 1/10 [04:55<44:19, 295.49s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.80s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:08<00:00, 124.13s/it]\u001b[A\n",
      " 20%|██        | 2/10 [09:34<38:07, 285.95s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:46<01:46, 106.56s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:32<00:00, 106.40s/it]\u001b[A\n",
      " 30%|███       | 3/10 [13:28<30:35, 262.15s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:59<01:59, 119.60s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:57<00:00, 118.98s/it]\u001b[A\n",
      " 40%|████      | 4/10 [18:19<27:21, 273.53s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.75s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:58<00:00, 119.11s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [22:44<22:32, 270.54s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:51<01:51, 111.09s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:47<00:00, 113.65s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [26:41<17:15, 258.91s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:51<01:51, 111.96s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:08<00:00, 124.05s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [31:48<13:43, 274.67s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:19<02:19, 139.01s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:08<00:00, 124.05s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [36:14<09:03, 271.94s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:03<02:03, 123.09s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:12<00:00, 126.10s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [40:48<04:32, 272.66s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:39<01:39, 99.93s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:21<00:00, 100.59s/it]\u001b[A\n",
      "100%|██████████| 10/10 [44:29<00:00, 266.98s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(210,230,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*60)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9955661-fa49-43a9-aa15-4357cc547c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:52<01:52, 112.61s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:46<00:00, 113.20s/it]\u001b[A\n",
      "100%|██████████| 1/1 [03:47<00:00, 227.41s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(258,260,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*60)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf58bd4e-bcb3-4856-963d-5e044a789851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:03<02:03, 123.63s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:18<00:00, 129.12s/it]\u001b[A\n",
      " 10%|█         | 1/10 [05:17<47:35, 317.26s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:59<01:59, 119.24s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:09<00:00, 124.55s/it]\u001b[A\n",
      " 20%|██        | 2/10 [09:43<38:17, 287.17s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:47<01:47, 107.94s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:36<00:00, 108.31s/it]\u001b[A\n",
      " 30%|███       | 3/10 [14:19<32:53, 281.90s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:08<02:08, 128.36s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:18<00:00, 129.47s/it]\u001b[A\n",
      " 40%|████      | 4/10 [19:21<29:01, 290.22s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:49<01:49, 109.94s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:49<00:00, 114.69s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [24:09<24:05, 289.20s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:59<01:59, 119.50s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:04<00:00, 122.50s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [28:24<18:30, 277.57s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:03<02:03, 123.36s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:50<00:00, 115.15s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [33:00<13:51, 277.16s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:12<02:12, 132.20s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:15<00:00, 127.73s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [37:25<09:06, 273.12s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:16<02:16, 136.47s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:01<00:00, 120.99s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [42:19<04:39, 279.65s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:04<02:04, 124.42s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:07<00:00, 123.71s/it]\u001b[A\n",
      "100%|██████████| 10/10 [47:24<00:00, 284.46s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(270,290,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*60)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce4a2817-f0af-4359-b1ea-9076611d87db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:02<02:02, 122.72s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:46<00:00, 113.42s/it]\u001b[A\n",
      "  6%|▌         | 1/17 [04:20<1:09:33, 260.86s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:35<01:35, 95.12s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:21<00:00, 100.78s/it]\u001b[A\n",
      " 12%|█▏        | 2/17 [07:58<58:51, 235.40s/it]  \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:14<02:14, 134.11s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:25<00:00, 132.58s/it]\u001b[A\n",
      " 18%|█▊        | 3/17 [13:15<1:03:38, 272.74s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:44<01:44, 104.36s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:45<00:00, 112.92s/it]\u001b[A\n",
      " 24%|██▎       | 4/17 [17:58<59:57, 276.73s/it]  \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:49<01:49, 109.43s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:44<00:00, 112.13s/it]\u001b[A\n",
      " 29%|██▉       | 5/17 [22:50<56:28, 282.34s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:51<01:51, 111.68s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:40<00:00, 110.30s/it]\u001b[A\n",
      " 35%|███▌      | 6/17 [27:09<50:17, 274.28s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:07<02:07, 127.44s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:19<00:00, 129.90s/it]\u001b[A\n",
      " 41%|████      | 7/17 [33:08<50:19, 301.92s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:06<02:06, 126.54s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:21<00:00, 130.74s/it]\u001b[A\n",
      " 47%|████▋     | 8/17 [39:02<47:47, 318.65s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:45<01:45, 105.29s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:53<00:00, 116.52s/it]\u001b[A\n",
      " 53%|█████▎    | 9/17 [43:06<39:22, 295.33s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.55s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:47<00:00, 113.62s/it]\u001b[A\n",
      " 59%|█████▉    | 10/17 [48:20<35:06, 300.87s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:43<01:43, 103.16s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:55<00:00, 117.94s/it]\u001b[A\n",
      " 65%|██████▍   | 11/17 [52:20<28:15, 282.52s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:04<02:04, 124.69s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:46<00:00, 113.36s/it]\u001b[A\n",
      " 71%|███████   | 12/17 [56:56<23:22, 280.46s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:55<01:55, 115.14s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:54<00:00, 117.10s/it]\u001b[A\n",
      " 76%|███████▋  | 13/17 [1:01:52<19:00, 285.23s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:02<02:02, 122.12s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:07<00:00, 123.56s/it]\u001b[A\n",
      " 82%|████████▏ | 14/17 [1:06:49<14:25, 288.53s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:12<02:12, 132.27s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:55<00:00, 117.81s/it]\u001b[A\n",
      " 88%|████████▊ | 15/17 [1:12:08<09:55, 297.90s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:12<02:12, 132.95s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:12<00:00, 126.30s/it]\u001b[A\n",
      " 94%|█████████▍| 16/17 [1:17:25<05:03, 303.54s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:03<02:03, 123.80s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:51<00:00, 115.70s/it]\u001b[A\n",
      "100%|██████████| 17/17 [1:22:54<00:00, 292.63s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(296,330,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*100)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9270e41f-13b2-41f5-bc04-dd168a02c340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:14<02:14, 134.03s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:23<00:00, 131.65s/it]\u001b[A\n",
      " 10%|█         | 1/10 [05:47<52:05, 347.32s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:06<02:06, 126.15s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:51<00:00, 115.65s/it]\u001b[A\n",
      " 20%|██        | 2/10 [09:54<38:27, 288.50s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:06<02:06, 126.32s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:13<00:00, 126.71s/it]\u001b[A\n",
      " 30%|███       | 3/10 [15:38<36:35, 313.57s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:02<02:02, 122.44s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:49<00:00, 114.99s/it]\u001b[A\n",
      " 40%|████      | 4/10 [19:58<29:14, 292.42s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:40<01:40, 100.36s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:43<00:00, 111.92s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [23:45<22:25, 269.14s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:55<01:55, 115.17s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:59<00:00, 119.58s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [29:01<18:59, 284.79s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:43<01:43, 103.87s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:01<00:00, 120.89s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [34:09<14:37, 292.64s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:56<01:56, 116.08s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:53<00:00, 116.68s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [39:42<10:10, 305.29s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:02<02:02, 122.17s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:56<00:00, 118.28s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [45:17<05:14, 314.76s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:53<01:53, 113.69s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:31<00:00, 105.73s/it]\u001b[A\n",
      "100%|██████████| 10/10 [50:23<00:00, 302.33s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(330,350,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*100)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cfa1c2-ae76-443b-90f4-08408e1b81bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:50<01:50, 110.95s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:50<00:00, 115.39s/it]\u001b[A\n",
      " 25%|██▌       | 1/4 [04:06<12:20, 246.79s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:01<02:01, 121.45s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:55<00:00, 117.56s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [08:20<08:22, 251.12s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:59<01:59, 119.46s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:52<00:00, 116.40s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [13:36<04:40, 280.67s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:10<02:10, 130.26s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:21<00:00, 130.77s/it]\u001b[A\n",
      "100%|██████████| 4/4 [18:58<00:00, 284.59s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(362,370,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*100)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8f6c7f-5eba-48d4-aae4-afe70aa626bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:59<01:59, 119.82s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:09<00:00, 124.84s/it]\u001b[A\n",
      " 10%|█         | 1/10 [05:29<49:27, 329.69s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:11<02:11, 131.84s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:14<00:00, 127.12s/it]\u001b[A\n",
      " 20%|██        | 2/10 [11:09<44:47, 335.91s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:10<02:10, 130.73s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:05<00:00, 122.64s/it]\u001b[A\n",
      " 30%|███       | 3/10 [16:32<38:27, 329.69s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:18<02:18, 138.84s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:11<00:00, 125.80s/it]\u001b[A\n",
      " 40%|████      | 4/10 [21:14<31:06, 311.11s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:47<01:47, 107.14s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:00<00:00, 120.31s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [26:51<26:41, 320.32s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:02<02:02, 122.33s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:09<00:00, 124.57s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [32:28<21:44, 326.04s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.42s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:58<00:00, 119.11s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [38:02<16:26, 328.72s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:16<02:16, 136.39s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:36<00:00, 138.39s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [43:37<11:01, 330.66s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:14<02:14, 134.44s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:23<00:00, 131.77s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [49:20<05:34, 334.38s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:48<01:48, 108.15s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:47<00:00, 113.57s/it]\u001b[A\n",
      "100%|██████████| 10/10 [53:26<00:00, 320.64s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(370,390,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*100)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da017c6-0287-4b3a-886d-75344c72fa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:46<01:46, 106.63s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:41<00:00, 110.70s/it]\u001b[A\n",
      " 20%|██        | 1/5 [04:09<16:37, 249.42s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:10<02:10, 130.36s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:16<00:00, 128.05s/it]\u001b[A\n",
      " 40%|████      | 2/5 [09:21<14:18, 286.30s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:44<01:44, 104.34s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:56<00:00, 118.02s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [14:22<09:46, 293.05s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:05<02:05, 125.37s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:52<00:00, 116.14s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [19:52<05:07, 307.76s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:08<02:08, 128.11s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:59<00:00, 119.78s/it]\u001b[A\n",
      "100%|██████████| 5/5 [24:55<00:00, 299.10s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(400,410,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*100)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e02d0379-4c42-4e5a-961f-cd1e386dc492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:53<01:53, 113.95s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:56<00:00, 118.34s/it]\u001b[A\n",
      " 10%|█         | 1/10 [05:32<49:54, 332.70s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:59<01:59, 119.22s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:41<00:00, 110.62s/it]\u001b[A\n",
      " 20%|██        | 2/10 [10:43<42:40, 320.08s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:45<01:45, 105.68s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:46<00:00, 113.17s/it]\u001b[A\n",
      " 30%|███       | 3/10 [14:36<32:40, 280.02s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:14<02:14, 134.42s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:29<00:00, 134.70s/it]\u001b[A\n",
      " 40%|████      | 4/10 [20:10<30:08, 301.49s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:59<01:59, 119.41s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:12<00:00, 126.34s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [25:06<24:57, 299.40s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:11<02:11, 131.34s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:57<00:00, 118.69s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [30:42<20:47, 311.98s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:43<01:43, 103.34s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:37<00:00, 108.58s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [35:58<15:40, 313.36s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:05<02:05, 125.85s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:12<00:00, 126.18s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [41:49<10:50, 325.14s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:05<02:05, 125.28s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:16<00:00, 128.16s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [47:05<05:22, 322.39s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:56<01:56, 116.70s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:47<00:00, 113.81s/it]\u001b[A\n",
      "100%|██████████| 10/10 [51:01<00:00, 306.14s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(410,430,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*100)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40332bfc-5b30-4937-aa6f-8d0eab2d1520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:08<02:08, 128.26s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:17<00:00, 128.76s/it]\u001b[A\n",
      "100%|██████████| 1/1 [04:46<00:00, 286.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(448,450,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*100)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2f15ef1-38d8-40c0-bd98-71a6c434b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:03<02:03, 123.05s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:14<00:00, 127.20s/it]\u001b[A\n",
      " 10%|█         | 1/10 [05:36<50:27, 336.41s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:53<01:53, 113.70s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:39<00:00, 109.63s/it]\u001b[A\n",
      " 20%|██        | 2/10 [11:07<44:27, 333.39s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.43s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:05<00:00, 122.79s/it]\u001b[A\n",
      " 30%|███       | 3/10 [15:59<36:40, 314.31s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:05<02:05, 125.88s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:11<00:00, 125.70s/it]\u001b[A\n",
      " 40%|████      | 4/10 [21:55<33:05, 330.93s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:52<01:52, 112.04s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:58<00:00, 119.45s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [25:56<24:52, 298.46s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.29s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:53<00:00, 116.60s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [30:53<19:52, 298.03s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:10<02:10, 130.32s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:25<00:00, 132.65s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [37:16<16:16, 325.59s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:03<02:03, 123.00s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:47<00:00, 113.94s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [43:02<11:04, 332.37s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:04<02:04, 124.21s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:03<00:00, 121.65s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [48:41<05:34, 334.22s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:11<02:11, 131.64s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:20<00:00, 130.28s/it]\u001b[A\n",
      "100%|██████████| 10/10 [53:41<00:00, 322.19s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(460,480,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*120)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e292f65f-cfaf-428b-8fd4-9167a17ceee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:09<02:09, 129.59s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:15<00:00, 127.61s/it]\u001b[A\n",
      " 25%|██▌       | 1/4 [06:07<18:21, 367.23s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:45<01:45, 105.35s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:52<00:00, 116.00s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [10:57<10:43, 321.82s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:11<02:11, 131.27s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:25<00:00, 132.67s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [16:54<05:38, 338.05s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:47<01:47, 107.05s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:53<00:00, 116.64s/it]\u001b[A\n",
      "100%|██████████| 4/4 [21:55<00:00, 328.98s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(492,500,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*120)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "670b6ec9-0f96-4aff-9bf3-5d4a31e10fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.71s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:11<00:00, 125.62s/it]\u001b[A\n",
      "100%|██████████| 1/1 [06:08<00:00, 368.25s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(548,550,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*120)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28d4f3c-f2c6-4517-bf24-e0460918b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:50<01:50, 110.07s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:32<00:00, 106.11s/it]\u001b[A\n",
      "  6%|▌         | 1/17 [05:07<1:21:55, 307.24s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:49<01:49, 109.24s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:55<00:00, 117.53s/it]\u001b[A\n",
      " 12%|█▏        | 2/17 [09:04<1:06:29, 265.98s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:55<01:55, 115.20s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:45<00:00, 112.61s/it]\u001b[A\n",
      " 18%|█▊        | 3/17 [12:59<58:47, 251.94s/it]  \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:59<01:59, 119.37s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:12<00:00, 126.21s/it]\u001b[A\n",
      " 24%|██▎       | 4/17 [18:40<1:02:14, 287.27s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:45<01:45, 105.95s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:47<00:00, 113.53s/it]\u001b[A\n",
      " 29%|██▉       | 5/17 [24:11<1:00:32, 302.71s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:48<01:48, 108.81s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:53<00:00, 116.66s/it]\u001b[A\n",
      " 35%|███▌      | 6/17 [28:51<54:06, 295.10s/it]  \n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:03<02:03, 123.76s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:11<00:00, 125.99s/it]\u001b[A\n",
      " 41%|████      | 7/17 [35:02<53:19, 319.91s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:11<02:11, 131.16s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:21<00:00, 130.78s/it]\u001b[A\n",
      " 47%|████▋     | 8/17 [39:42<46:06, 307.39s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:04<02:04, 124.62s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:08<00:00, 124.00s/it]\u001b[A\n",
      " 53%|█████▎    | 9/17 [45:50<43:28, 326.03s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:03<02:03, 123.77s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:54<00:00, 117.28s/it]\u001b[A\n",
      " 59%|█████▉    | 10/17 [51:42<38:59, 334.22s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:06<02:06, 126.17s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:58<00:00, 119.06s/it]\u001b[A\n",
      " 65%|██████▍   | 11/17 [56:58<32:52, 328.69s/it]\n",
      "  0%|          | 0/2 [01:26<?, ?it/s]\u001b[A\n",
      " 65%|██████▍   | 11/17 [59:55<32:41, 326.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\EHSAN~1.EST\\AppData\\Local\\Temp/ipykernel_14360/3217344533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m566\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mFinalCollector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\EHSAN~1.EST\\AppData\\Local\\Temp/ipykernel_14360/4110660939.py\u001b[0m in \u001b[0;36mFinalCollector\u001b[1;34m(_from, _to)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mdff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLexicon_List_Wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_from\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0m_to\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mdff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPaperGrabber\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data_from_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_from\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_to_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mdff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\EHSAN~1.EST\\AppData\\Local\\Temp/ipykernel_14360/4110660939.py\u001b[0m in \u001b[0;36mPaperGrabber\u001b[1;34m(keyword, depth)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#from 5 to 30 seconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mbibitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_query\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mcontainer_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbibitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'container_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'container_type'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbibitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(566,600,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*120)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77526f8b-76e8-46a1-84b6-1f69ebbe1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "588-0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7232787-9474-4638-a0a3-3274bb7393ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:12<02:12, 132.83s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:23<00:00, 131.95s/it]\u001b[A\n",
      " 17%|█▋        | 1/6 [05:15<26:19, 315.90s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:59<01:59, 119.76s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:39<00:00, 109.81s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [10:43<21:31, 322.80s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:07<02:07, 127.90s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:12<00:00, 126.41s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [15:13<14:55, 298.61s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:50<01:50, 110.51s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:54<00:00, 117.46s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [19:12<09:10, 275.05s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:52<01:52, 112.16s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:48<00:00, 114.27s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [24:44<04:55, 295.78s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:13<02:13, 133.51s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:19<00:00, 129.56s/it]\u001b[A\n",
      "100%|██████████| 6/6 [31:01<00:00, 310.33s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(588,600,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*120)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385c8032-d6b5-450b-82e8-5c24afc28a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:08<02:08, 128.95s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:16<00:00, 128.12s/it]\u001b[A\n",
      "  6%|▌         | 1/18 [05:22<1:31:18, 322.27s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:04<02:04, 124.13s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:10<00:00, 125.28s/it]\u001b[A\n",
      " 11%|█         | 2/18 [11:00<1:28:29, 331.86s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:11<02:11, 131.49s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:25<00:00, 132.52s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [17:11<1:27:26, 349.75s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [03:11<03:11, 191.13s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [21:08<1:45:40, 422.68s/it]\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\EHSAN~1.EST\\AppData\\Local\\Temp/ipykernel_30988/696274134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m634\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m670\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mFinalCollector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\EHSAN~1.EST\\AppData\\Local\\Temp/ipykernel_30988/4110660939.py\u001b[0m in \u001b[0;36mFinalCollector\u001b[1;34m(_from, _to)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mdff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLexicon_List_Wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_from\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0m_to\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mdff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPaperGrabber\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data_from_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_from\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_to_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mdff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\EHSAN~1.EST\\AppData\\Local\\Temp/ipykernel_30988/4110660939.py\u001b[0m in \u001b[0;36mPaperGrabber\u001b[1;34m(keyword, depth)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#from 5 to 30 seconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mbibitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_query\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mcontainer_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbibitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'container_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'container_type'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbibitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbibitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bib'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scholarly\\publication_parser.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;31m# Pickle protocol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(634,670,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*120)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e110bd0-5362-4712-9758-c2e33b8243e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:14<02:14, 134.51s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:19<00:00, 129.67s/it]\u001b[A\n",
      " 11%|█         | 1/9 [06:17<50:18, 377.35s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:56<01:56, 116.84s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:34<00:00, 107.38s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [11:00<37:32, 321.72s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:01<02:01, 121.29s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:08<00:00, 124.44s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [17:02<34:00, 340.06s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:46<01:46, 106.04s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:38<00:00, 109.48s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [22:26<27:50, 334.10s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:37<01:37, 97.38s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:41<00:00, 110.76s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [26:44<20:25, 306.49s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:04<02:04, 124.60s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:18<00:00, 129.37s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [32:30<15:59, 319.84s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:49<01:49, 109.58s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:37<00:00, 108.70s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [38:02<10:47, 323.95s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:10<02:10, 130.85s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:15<00:00, 127.71s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [43:38<05:27, 327.61s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:11<02:11, 131.79s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:17<00:00, 128.92s/it]\u001b[A\n",
      "100%|██████████| 9/9 [48:48<00:00, 325.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(652,670,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*120)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0333a6f1-de7e-4dd4-a8e8-4d41597ac8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.93s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:54<00:00, 117.39s/it]\u001b[A\n",
      " 17%|█▋        | 1/6 [05:28<27:24, 328.86s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:03<02:03, 123.01s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:12<00:00, 126.29s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [11:40<23:35, 353.99s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:09<02:09, 129.97s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:03<00:00, 121.87s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [17:43<17:53, 357.99s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:08<02:08, 128.73s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:44<00:00, 112.28s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [21:56<10:33, 316.77s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:10<02:10, 130.74s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:20<00:00, 130.02s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [27:27<05:21, 321.92s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:07<02:07, 127.86s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:20<00:00, 130.08s/it]\u001b[A\n",
      "100%|██████████| 6/6 [32:42<00:00, 327.16s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(678,690,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*120)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c20ed1-eb10-4e80-9462-8a84985c135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:50<01:50, 110.25s/it]\u001b[A\n",
      "100%|██████████| 2/2 [03:37<00:00, 108.91s/it]\u001b[A\n",
      "100%|██████████| 1/1 [04:07<00:00, 247.82s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(690,692,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*120)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "839d74aa-ff3a-43f5-901d-ed136266bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [01:30<00:00, 90.01s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(696,698,2)): \n",
    "    time.sleep(np.floor(abs(np.sin(np.random.random()*(20 + np.random.random())))*120)) \n",
    "    FinalCollector(i,i+2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "id": "aa5bcd16-6ea6-46ba-9a04-23777e8ed147",
=======
   "execution_count": 1,
   "id": "e5adb3e1-2530-4912-b964-210644899aa6",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.12.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.96)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.5.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.6.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.18.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.8.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ec4822-1b57-44db-8984-eba93157c211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a811dc8a78d543008705fdf134b14ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0bb82eb83642a682c7284e76dc5dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea403c0d9f04989a78fed90d6ee1885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3634c73cf21d4ecaac8c09849f439702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaec52828a1e44e29d9349fd8b45dcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcfd17d621046e696459d863f863fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b452bd7e9d47e1b753a64297fdcaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed55099686584886b6a581d93b58eafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38019fd4c46c471fa8ba93ee02bfe098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d68a3599624dbaa51d24718d49844b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e11bab5766486f9b9c8a83d7c34aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78242aa93d1f4428921539640fa95bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This framework generates embeddings for each input sentence\n",
      "Embedding: [-1.76214486e-01  1.20601453e-01 -2.93623954e-01 -2.29857937e-01\n",
      " -8.22924078e-02  2.37709492e-01  3.39985013e-01 -7.80964196e-01\n",
      "  1.18127584e-01  1.63373947e-01 -1.37715489e-01  2.40282848e-01\n",
      "  4.25125599e-01  1.72417849e-01  1.05279572e-01  5.18164098e-01\n",
      "  6.22215830e-02  3.99285525e-01 -1.81652397e-01 -5.85578501e-01\n",
      "  4.49720696e-02 -1.72750369e-01 -2.68443197e-01 -1.47386253e-01\n",
      " -1.89218149e-01  1.92150772e-01 -3.83842617e-01 -3.96007121e-01\n",
      "  4.30648863e-01 -3.15319747e-01  3.65949750e-01  6.05160743e-02\n",
      "  3.57325733e-01  1.59736335e-01 -3.00983965e-01  2.63250053e-01\n",
      " -3.94311100e-01  1.84855714e-01 -3.99549127e-01 -2.67889470e-01\n",
      " -5.45117259e-01 -3.13403420e-02 -4.30644184e-01  1.33278340e-01\n",
      " -1.74793929e-01 -4.35465604e-01 -4.77379143e-01  7.12554604e-02\n",
      " -7.37002268e-02  5.69136798e-01 -2.82579511e-01  5.24975024e-02\n",
      " -8.20007980e-01  1.98296815e-01  1.69511944e-01  2.71780223e-01\n",
      "  2.64610946e-01 -2.55737770e-02 -1.74096197e-01  1.63314268e-01\n",
      " -3.95260990e-01 -3.17559391e-02 -2.62555987e-01  3.52754533e-01\n",
      "  3.01434815e-01 -1.47197157e-01  2.10075706e-01 -1.84010535e-01\n",
      " -4.12896037e-01  4.14775699e-01 -1.89769521e-01 -1.35482490e-01\n",
      " -3.79272312e-01 -4.68023457e-02 -3.33600715e-02  9.00394469e-02\n",
      " -3.30132961e-01 -3.87319103e-02  3.75082135e-01 -1.46996439e-01\n",
      "  4.34959620e-01  5.38325727e-01 -2.65445352e-01  1.64445952e-01\n",
      "  4.17078704e-01 -4.72508930e-02 -7.48732686e-02 -4.26260918e-01\n",
      " -1.96994469e-01  6.10317364e-02 -4.74262655e-01 -6.48334742e-01\n",
      "  3.71462494e-01  2.50957131e-01  1.22529730e-01  8.88768137e-02\n",
      " -1.06724463e-01  5.33983745e-02  9.74506214e-02 -3.46658863e-02\n",
      " -1.02882698e-01  2.32288972e-01 -2.53739655e-01 -5.13112366e-01\n",
      "  1.85216293e-01 -3.04357737e-01 -3.55212763e-02 -1.26975372e-01\n",
      " -7.71633014e-02 -5.15329897e-01 -2.28071928e-01  2.03343648e-02\n",
      "  7.38177001e-02 -1.52558520e-01 -4.00837749e-01 -2.47749329e-01\n",
      "  3.97470117e-01 -2.60260522e-01  2.50906289e-01  1.68228790e-01\n",
      "  1.33900553e-01 -2.10832562e-02 -4.70035374e-01  4.78850186e-01\n",
      "  2.80345410e-01 -4.64546710e-01  3.21746856e-01  2.34207466e-01\n",
      "  2.45772213e-01 -4.71482307e-01  5.00401139e-01  4.10189956e-01\n",
      "  5.15216887e-01  2.62549341e-01  2.11594291e-02 -3.89687389e-01\n",
      " -2.41742849e-01 -2.14834601e-01 -8.62649977e-02 -1.65323257e-01\n",
      " -5.21894731e-02  3.41875046e-01  4.50314373e-01 -3.06973577e-01\n",
      " -2.02294186e-01  6.85521781e-01 -5.33892512e-01  3.58471572e-01\n",
      "  1.45286530e-01 -7.07054734e-02 -1.50529251e-01 -8.56280178e-02\n",
      " -7.67850950e-02  1.89544767e-01 -1.04067571e-01  5.33544064e-01\n",
      " -5.27887166e-01  2.42331326e-02 -2.64347941e-01 -2.23186731e-01\n",
      " -3.81208599e-01  7.59914368e-02 -4.64484960e-01 -3.36549163e-01\n",
      "  4.21229720e-01  1.07479200e-01  1.90457717e-01  2.89474777e-03\n",
      " -1.08513847e-01  1.53545365e-01  3.16023409e-01 -2.70838737e-02\n",
      " -5.40594518e-01  8.97285640e-02 -1.15549788e-01  3.97803754e-01\n",
      " -4.97683227e-01 -2.84893215e-01  4.99860980e-02  3.61279517e-01\n",
      "  6.90535784e-01  1.46821558e-01  1.73396751e-01 -1.74582422e-01\n",
      " -3.15702498e-01  6.73003420e-02  2.17250258e-01  9.78535414e-02\n",
      " -1.29472479e-01 -1.86929494e-01  1.34878054e-01 -1.53885201e-01\n",
      "  7.44716004e-02 -1.85536087e-01 -2.80628473e-01 -1.14144310e-01\n",
      "  4.12249714e-01  6.39495328e-02 -1.45715281e-01 -9.82061774e-02\n",
      " -1.33081809e-01 -1.88410655e-01 -2.84839235e-02 -3.49510834e-02\n",
      "  3.34257185e-02  6.98896646e-02  1.90354556e-01 -2.96724170e-01\n",
      "  2.64707906e-03  1.09140873e-01  1.70892403e-02  2.60589451e-01\n",
      "  3.29038471e-01 -6.61559179e-02  2.39665329e-01 -2.26194382e-01\n",
      " -3.36869508e-02  1.49400026e-01 -3.21265548e-01 -2.68577933e-01\n",
      "  5.72631598e-01 -4.92308497e-01  2.00666681e-01 -3.49261761e-01\n",
      " -2.89886799e-02  6.09010458e-01 -5.72333157e-01  2.35000461e-01\n",
      "  6.47177035e-03 -3.14952880e-02  2.78106220e-02 -3.90340805e-01\n",
      " -2.08949938e-01 -3.04452717e-01 -7.20198080e-02 -8.29840600e-02\n",
      "  3.73792946e-01  7.38937706e-02 -2.21075509e-02  9.88140032e-02\n",
      " -1.51426822e-01 -1.40431061e-01  2.26018026e-01  2.76090056e-01\n",
      " -8.87750387e-02 -1.12815946e-01 -2.66286165e-01  2.77834415e-01\n",
      " -4.75612618e-02  6.71004131e-02 -2.78585516e-02 -2.39991229e-02\n",
      "  2.51708657e-01  4.68793899e-01 -5.39325476e-01  1.10598274e-01\n",
      " -3.44947278e-01  4.15990025e-01  7.28482977e-02 -3.19647312e-01\n",
      "  4.90374506e-01 -7.30346935e-03 -2.64269975e-03  9.63711202e-01\n",
      "  3.23884964e-01 -7.79616535e-02 -2.37589210e-01  2.34038457e-01\n",
      " -3.16054076e-01 -1.65642228e-03 -1.09070647e+00  3.38409215e-01\n",
      "  4.70606945e-02  1.07435457e-01 -2.06672296e-01  4.26458521e-03\n",
      " -1.38443254e-03 -5.31455636e-01 -2.75648654e-01 -1.64648756e-01\n",
      " -3.42916459e-01 -4.26118851e-01  6.01811886e-01  4.55971926e-01\n",
      " -2.72701681e-01 -3.45803872e-02  2.62752354e-01 -6.34192629e-03\n",
      "  2.79631108e-01 -2.53558904e-01 -1.68626443e-01  3.82933393e-02\n",
      "  2.07763016e-01 -4.31525975e-01 -7.24000633e-02 -1.26854405e-01\n",
      "  2.07029767e-02  5.74441373e-01  3.54672581e-01  9.28304270e-02\n",
      "  6.70506805e-02  1.11520581e-01 -1.86513588e-02  4.62352008e-01\n",
      "  2.72504687e-01 -3.60474110e-01  5.29415548e-01 -1.00311288e-03\n",
      " -8.81363079e-02  1.49975389e-01  5.25862016e-02  4.63517606e-01\n",
      " -3.96831453e-01  2.42640659e-01 -2.08912343e-01  3.65672141e-01\n",
      " -4.73766937e-04  5.33963323e-01 -1.97879568e-01  3.11583042e-01\n",
      " -6.96714938e-01 -4.29500729e-01 -4.49359536e-01 -2.71370374e-02\n",
      " -6.98710009e-02  2.06174776e-01 -1.57107770e-01  4.43521291e-01\n",
      " -6.74268678e-02 -3.00924182e-01  5.14859498e-01  3.36029887e-01\n",
      "  6.63376972e-02 -1.15235180e-01 -2.95979548e-02  2.79471695e-01\n",
      " -3.48200239e-02 -7.29322359e-02 -4.58473414e-02  1.54262766e-01\n",
      "  8.09356391e-01  5.20327985e-01 -4.02114570e-01 -3.23152766e-02\n",
      " -1.10364199e-01  7.50504658e-02 -1.51098385e-01  8.45740259e-01\n",
      " -1.80843920e-01  3.22573602e-01  1.04708351e-01  3.19663554e-01\n",
      " -1.55085266e-01  1.69236585e-01 -2.56996512e-01  2.01208860e-01\n",
      "  1.77393183e-01 -2.74333119e-01 -3.36944431e-01  5.02356708e-01\n",
      " -1.18357331e-01 -2.01167092e-01 -5.36485791e-01 -7.69809783e-02\n",
      "  1.15383286e-02 -2.36464337e-01 -2.98773646e-02  1.31366715e-01\n",
      "  2.94184268e-01  9.90917981e-02 -5.43897927e-01  1.40812814e-01\n",
      "  3.66998613e-01  5.04859723e-02  1.99122503e-01 -2.80674398e-01\n",
      "  4.34192300e-01 -1.40274972e-01  5.78048527e-01  1.77715704e-01\n",
      "  8.98363069e-02  3.29651892e-01  6.13010116e-02 -3.24933648e-01]\n",
      "\n",
      "Sentence: Sentences are passed as a list of string.\n",
      "Embedding: [ 0.32208735 -0.00123898  0.17937383 -0.36919165 -0.06460278  0.09153698\n",
      "  0.241191   -0.29494205  0.07728963  0.11577012 -0.0447998   0.17928247\n",
      "  0.14753617  0.21511646  0.36810797  0.20910892  0.27194235  0.34880075\n",
      " -0.57251954 -0.18253212  0.44489577  0.27452973  0.04266286 -0.07683557\n",
      "  0.18689114  0.44965038 -0.16932605 -0.24896337 -0.20479259  0.40285045\n",
      " -0.21019231  0.03775721  0.07848534  0.12848443  0.02593085  0.47155982\n",
      "  0.1785381  -0.07379765  0.08130746 -0.23328748 -0.49801254 -0.04135707\n",
      " -0.12094588  0.17028989 -0.19154072 -0.38459817 -0.77479136 -0.10622723\n",
      " -0.23044878  0.4024145  -0.87450904  0.23853727 -0.4712988   0.21262194\n",
      "  0.33409345 -0.24154015 -0.14835095 -0.14513548 -0.34830934 -0.08349235\n",
      " -0.6909727  -0.2984524  -0.12230491  0.07482665 -0.18775596 -0.3754649\n",
      "  0.21369524 -0.1009641  -0.12234456  0.31431544 -0.23989949  0.2246076\n",
      "  0.03995978  0.3603484  -0.5663804   0.21883482  0.11020274 -0.10870814\n",
      "  0.07084078 -0.02608177  0.18370342  0.08465947 -0.20478235 -0.24435607\n",
      " -0.08180576 -0.01903118 -0.0359137   0.0239845  -0.2855853   0.07374781\n",
      " -0.2974423  -0.8771787   0.47101936 -0.04940459  0.36394498  0.48264396\n",
      "  0.01564628  0.03558925 -0.26202986 -0.11218464  0.02411023  0.3747778\n",
      " -0.09897291 -0.09851857  0.15000834  0.00689528 -0.12652436 -0.3159893\n",
      "  0.31449506 -0.29425615 -0.2694104   0.20221192  0.14329918 -0.19584642\n",
      " -0.3410444  -0.03172769  0.7365029   0.3192349   0.24381304  0.30732593\n",
      "  0.09933233  0.19010934 -0.10694556  0.05178659  0.03233431 -0.10314641\n",
      "  0.26499212  0.3120647   0.43152618 -0.6426123   0.08409589 -0.04327346\n",
      " -0.04991202 -0.1271855   0.1378919   0.0130622   0.34383246  0.09234308\n",
      " -0.09922745 -0.52159905  0.25842252 -0.01057143 -0.00478195  0.03938866\n",
      "  0.190861    0.32933888 -0.2434517  -0.07328323 -0.39280033  0.14541803\n",
      "  0.3283954  -0.04184612  0.07407147 -0.73860526 -0.09075996  0.15802313\n",
      " -0.09780037 -0.21605982 -0.30027458  0.23236589  0.01072448  0.49570477\n",
      "  0.04974853  0.2993143  -0.05382278  0.3532811   0.34191754  0.49667242\n",
      " -0.4860527  -0.19098854  0.8154577   0.22962637 -0.32077792 -0.3272671\n",
      " -0.3677171   0.3452115  -0.02620158 -0.14315048  0.10648423 -0.24638033\n",
      " -0.09366622  0.17198648 -0.08508807  0.20120293 -0.05879221 -0.34020996\n",
      " -0.19565333  0.28280887  0.20124315 -0.08207275  0.09779127 -0.2637501\n",
      "  0.12176558 -0.01041483 -0.4385982   0.11058234  0.480104   -0.10981987\n",
      " -0.63754576  0.2933681  -0.1920763   0.46536988  0.27042007  0.19388466\n",
      "  0.17379028 -0.30076995 -0.02751219 -0.02291252  0.3678463   0.02492169\n",
      "  0.53705496  0.18851237 -0.13344425  0.08917339  0.05542922 -0.24818307\n",
      " -0.04199773  0.05767391 -0.1827882  -0.41686466  0.16070575 -0.46362525\n",
      "  0.11769214 -0.3770692   0.02960381  0.69256103 -0.48308954  0.21128383\n",
      "  0.18214522 -0.18429618  0.0681766  -0.02460902 -0.19073628 -0.06737018\n",
      " -0.5670073  -0.23929308 -0.08497215  0.03093956  0.310799    0.12916304\n",
      "  0.05248251 -0.33449835  0.18810116  0.23547177 -0.0018347   0.45361587\n",
      "  0.24885082 -0.05641091 -0.2977459  -0.43511733 -0.07969429 -0.17670172\n",
      " -0.13347112  0.1938273   0.22002606 -0.11057549  0.2647375  -0.27179068\n",
      "  0.03410836 -0.47714433  0.44719073 -0.05570432  0.39643747  0.27483252\n",
      "  0.33305645 -0.10890245  0.27888158  0.21596923 -0.05252237 -0.3586755\n",
      " -0.69062924  0.03960175  0.0065279  -0.01095344 -0.10027698  0.0477004\n",
      " -0.3414694  -0.16714163  0.07136442 -0.18078464 -0.30248493 -0.6842873\n",
      " -0.09592856 -0.21411105 -0.65524364  0.5675644   0.26946738 -0.00190052\n",
      "  0.8618063   0.16771571  0.03102748 -0.26773044 -0.07830273 -0.48510894\n",
      " -0.26737225 -0.33354256 -0.57382524  0.35678264  0.08993577 -0.13057199\n",
      " -0.15136494 -0.06124145 -0.13037089  0.5585608   0.6141749  -0.04804046\n",
      " -0.06388576  0.08390605 -0.25143683 -0.0435985  -0.185258    0.04693374\n",
      " -0.34380868 -0.09738439  0.16833639  0.07526862  0.17694503  0.17727189\n",
      " -0.03423433  0.1499357  -0.1377315  -0.20949689 -0.6127284   0.3781394\n",
      "  0.3901827  -0.08359352  0.0315212   0.13122387  0.38826063  0.21844243\n",
      "  0.09724292  0.42089337 -0.32641256 -0.26933426 -0.3909512  -0.2264865\n",
      " -0.3202071  -0.16287412 -0.03581646  0.36373892  0.18583322 -0.02914022\n",
      " -0.4657794   0.2916891   0.3725129  -0.23726612  0.00338612  0.41540965\n",
      "  0.03300421  0.45003957 -0.08159244  0.3399034   0.244979    0.02352396\n",
      " -0.14643063 -0.12644528  0.31128648 -0.15182626  0.01009397  0.49108502\n",
      "  0.14362386  0.11589019 -0.23236984  0.24751768  0.18364534 -0.2483682\n",
      " -0.11220922 -0.2311336   0.0842898  -0.24378666  0.13307264  0.4235571\n",
      "  0.33348376 -0.3437014   0.03443664  0.18795529  0.20037192 -0.05355954\n",
      "  0.284853    0.07176603  0.05487147 -0.08103782  0.2707688   0.11700256]\n",
      "\n",
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Embedding: [ 0.5897934  -0.23598295 -0.25411728  0.00311636 -0.08485746 -0.26799768\n",
      " -0.07506641 -0.30021396  0.0515164   0.16585366  0.26076734  0.38256383\n",
      "  0.4373288  -0.09301949 -0.26568812 -0.09716269 -0.48096097  0.11878294\n",
      "  0.13675499  0.04712055 -0.23696536 -0.52332395 -0.0163186   0.06127293\n",
      " -0.74333024 -0.11898901 -0.7886533  -0.48108825  0.10314909 -0.32372472\n",
      "  0.8144372  -0.39774546 -0.5031555  -0.7972458  -0.63248235  0.3232099\n",
      " -0.3841946  -0.11186715 -0.13243574  0.02069694 -0.1430955  -0.0370119\n",
      "  0.06116609  0.16332905 -0.11174295  0.25234255 -1.0464071  -0.37252343\n",
      "  0.15601993 -0.29991603  0.19883879  0.23433428 -0.37025788  0.3173362\n",
      "  0.84428644  0.06977716  0.03273643  0.09948324 -0.31141305  0.5051773\n",
      "  0.0030931   0.380137    0.04582718  0.00633386 -0.00142923 -0.13568674\n",
      " -0.0761135  -0.2584429  -0.80221295  0.55085903 -0.09124395 -0.21782023\n",
      " -0.78810924 -0.5118383   0.46672526  0.5527475  -0.37124732 -0.18645374\n",
      "  0.35856965 -0.19586335  0.18042536 -0.42548898 -0.09681385 -0.05536832\n",
      "  0.52489287  0.24481155  0.01934668 -0.2963793  -0.12777822 -0.30534953\n",
      "  0.45349368  0.07469138 -0.0706171   0.26243007  0.3738397   0.14306368\n",
      "  0.00127863 -0.41776052 -0.24014099 -0.25093517  0.3484377   0.3114402\n",
      "  0.08087344 -0.57640547  0.54085284 -0.01802211 -0.12959813 -0.0739968\n",
      "  0.39369765  0.64883894 -0.02030023 -0.5665556   0.29675996  0.5200024\n",
      "  0.21538736  0.10369671  0.06199231  0.01896268 -0.1526921  -1.0642661\n",
      "  0.76149654  0.20734419  0.44718924  0.1449396   0.65802306 -0.09440911\n",
      " -0.2331636   0.42157087  0.11957657 -0.32571068  0.16425563 -0.495087\n",
      " -0.19516094 -0.5618325  -0.14933316  0.610941   -0.17897932 -0.01805551\n",
      " -0.5964051   0.04918578  0.1534781  -0.42829427  0.73295313 -0.352911\n",
      " -0.11159644  0.06127807 -0.2970442   0.43966627 -0.09660365  0.6557944\n",
      " -0.61403376  0.02576613  0.43827453  0.01733263 -0.40002277 -0.08178314\n",
      " -0.37126958  0.08230281 -0.13104376 -0.53261113 -0.29928342  0.69936603\n",
      " -0.04398763 -0.15702994  0.09794124 -0.03017473 -0.1000267   0.19996573\n",
      " -0.48188555  0.17949152  0.5656603  -0.11954787 -0.6963728   0.0525966\n",
      " -0.00549662  0.16739334 -0.31692904 -0.09747536  0.33193663  0.4719963\n",
      "  0.12653972  0.1913092   0.42949113  0.5529122   0.31463322 -0.31433102\n",
      " -0.41508687  0.32897687  0.35702726 -0.19209678  0.22239392 -0.4871788\n",
      "  0.34091583 -0.22137432 -0.12667583  0.21120834 -0.3134788   0.8468933\n",
      "  0.2011264  -0.4259875   0.5131572  -1.2351419   0.76971775 -0.17414246\n",
      " -0.0218114  -0.03568685 -1.1059492  -0.5720653   0.05585207  0.12461478\n",
      " -0.45065877  0.06428982 -0.16033866  0.3993291  -0.10322911 -0.02025508\n",
      " -0.18010466  0.06234768 -0.02188894 -0.1579542   0.2831697   0.02385279\n",
      "  0.03098137 -0.07853305  0.29896554 -0.06237325  0.5498678   0.17862324\n",
      "  0.2116475   0.4448335   0.04890737 -0.16238107 -0.226699    0.18871999\n",
      "  0.07943606  0.1359758  -0.18484493  1.1135513   0.8280954  -0.3120272\n",
      "  0.09506017  0.05096088  0.38804892  0.25000495  0.55848587  0.31088766\n",
      " -0.05318607 -0.07675359  0.15282293  0.09189977 -0.01429145  0.6657544\n",
      " -0.03346029 -0.4470352   0.8006746  -0.47992805  0.17478187 -0.30563843\n",
      "  0.5536524   0.4238099   0.48674312 -0.49677983 -0.45194814 -0.95563084\n",
      " -0.20709938 -0.22605729 -0.00999168  0.98797673  0.58807755  0.08305467\n",
      " -0.5578138   0.21136858 -0.3607223   0.52668476  0.3398358  -0.15756182\n",
      "  0.00423764 -0.05354533 -0.5777672   0.55951035 -0.05747126  0.16837658\n",
      "  0.37946865 -0.25776434  0.08421469 -0.15229928 -0.03280767  0.10083833\n",
      " -0.41858318 -0.4449904  -0.29309902  0.6144207   0.08548207 -0.0634957\n",
      " -0.6152549   0.7954411  -0.24058408  0.20638879 -0.51252586  0.6312015\n",
      "  0.36744308 -0.44009867  0.46913958  0.23087756 -0.13737981  0.21696903\n",
      "  0.4004326  -0.02490609 -1.1396756   0.02653874 -0.327302    0.09984118\n",
      "  0.05725689 -0.8472218   0.06451977  0.4569805   0.63563055  0.4518563\n",
      " -0.27519023  0.21346171  0.17374273  0.4282204  -0.6584537   0.4000257\n",
      " -0.02035555 -0.67307884 -1.0269238   0.1687727  -0.09248697 -0.79977626\n",
      "  0.3809339   0.51712334  0.04200972 -0.04867514 -0.18772249  0.16339518\n",
      " -0.21974933  0.21939264  0.03676505 -0.29750302 -0.37409687 -0.5209505\n",
      " -0.41314623 -0.48947704 -0.81896645  0.08531477  0.34576938  0.1250601\n",
      "  0.24945219 -0.25254658 -0.03156117  0.27573124 -0.60857147  0.3357\n",
      "  0.22913116  0.66070837 -0.30215812 -0.05315311  0.22247504  0.06138683\n",
      "  0.33555183 -0.08485214  0.0876459   0.10872056 -0.40389323 -0.14949797\n",
      "  0.19458477 -0.8106063   0.79730946 -0.4116257   0.01364179  0.23472969\n",
      " -0.09732241 -0.2904406   0.03843212 -0.07090494 -0.1740448  -0.44859388\n",
      " -0.31867257  0.4165605  -0.05431677  0.14036183  1.0559161   0.5301812 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.',\n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e418868f-f87c-4879-a810-525153186dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Using cached bertopic-0.10.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting pyyaml<6.0\n",
      "  Using cached PyYAML-5.4.1-cp39-cp39-win_amd64.whl (213 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic) (1.20.3)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic) (0.5.3)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic) (0.24.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic) (4.62.3)\n",
      "Requirement already satisfied: plotly>=4.7.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic) (5.6.0)\n",
      "Collecting hdbscan>=0.8.28\n",
      "  Using cached hdbscan-0.8.28.tar.gz (5.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.28->bertopic) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.28->bertopic) (1.7.1)\n",
      "Requirement already satisfied: cython>=0.27 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.28->bertopic) (0.29.24)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from plotly>=4.7.0->bertopic) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2.post1->bertopic) (2.2.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.12.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.96)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.5.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (3.6.5)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (1.11.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (4.18.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from tqdm>=4.41.1->bertopic) (0.4.4)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.54.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.5.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.37.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.10.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2021.8.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.12.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (21.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.3.1)\n",
      "Requirement already satisfied: click in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (1.26.7)\n",
      "Building wheels for collected packages: hdbscan\n",
      "  Building wheel for hdbscan (pyproject.toml): started\n",
      "  Building wheel for hdbscan (pyproject.toml): finished with status 'error'\n",
      "Failed to build hdbscan\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for hdbscan (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [40 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\hdbscan_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\plots.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\prediction.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\robust_single_linkage_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\validity.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_hdbscan.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_prediction_utils.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_rsl.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  running build_ext\n",
      "  cythoning hdbscan/_hdbscan_tree.pyx to hdbscan\\_hdbscan_tree.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-1ecciy0q\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-nx1873l5\\hdbscan_e163528448ff49fab644dc5ddeb0516d\\hdbscan\\_hdbscan_tree.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_linkage.pyx to hdbscan\\_hdbscan_linkage.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-1ecciy0q\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-nx1873l5\\hdbscan_e163528448ff49fab644dc5ddeb0516d\\hdbscan\\_hdbscan_linkage.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_boruvka.pyx to hdbscan\\_hdbscan_boruvka.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-1ecciy0q\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-nx1873l5\\hdbscan_e163528448ff49fab644dc5ddeb0516d\\hdbscan\\_hdbscan_boruvka.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_reachability.pyx to hdbscan\\_hdbscan_reachability.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-1ecciy0q\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-nx1873l5\\hdbscan_e163528448ff49fab644dc5ddeb0516d\\hdbscan\\_hdbscan_reachability.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_prediction_utils.pyx to hdbscan\\_prediction_utils.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-1ecciy0q\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-nx1873l5\\hdbscan_e163528448ff49fab644dc5ddeb0516d\\hdbscan\\_prediction_utils.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/dist_metrics.pyx to hdbscan\\dist_metrics.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-1ecciy0q\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-nx1873l5\\hdbscan_e163528448ff49fab644dc5ddeb0516d\\hdbscan\\dist_metrics.pxd\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  building 'hdbscan._hdbscan_tree' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for hdbscan\n",
      "ERROR: Could not build wheels for hdbscan, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b60836-0eab-486b-a7de-cb42fc742ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic[flair]\n",
      "Note: you may need to restart the kernel to use updated packages.  Using cached bertopic-0.10.0-py2.py3-none-any.whl (58 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for hdbscan (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [40 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\hdbscan_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\plots.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\prediction.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\robust_single_linkage_.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\validity.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  copying hdbscan\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\n",
      "  creating build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_flat.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_hdbscan.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_prediction_utils.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\test_rsl.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  copying hdbscan\\tests\\__init__.py -> build\\lib.win-amd64-cpython-39\\hdbscan\\tests\n",
      "  running build_ext\n",
      "  cythoning hdbscan/_hdbscan_tree.pyx to hdbscan\\_hdbscan_tree.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-tofc60h5\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-24imy99a\\hdbscan_3aafd7b966b249cebac649891ae8a9dc\\hdbscan\\_hdbscan_tree.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_linkage.pyx to hdbscan\\_hdbscan_linkage.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-tofc60h5\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-24imy99a\\hdbscan_3aafd7b966b249cebac649891ae8a9dc\\hdbscan\\_hdbscan_linkage.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_boruvka.pyx to hdbscan\\_hdbscan_boruvka.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-tofc60h5\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-24imy99a\\hdbscan_3aafd7b966b249cebac649891ae8a9dc\\hdbscan\\_hdbscan_boruvka.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_hdbscan_reachability.pyx to hdbscan\\_hdbscan_reachability.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-tofc60h5\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-24imy99a\\hdbscan_3aafd7b966b249cebac649891ae8a9dc\\hdbscan\\_hdbscan_reachability.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/_prediction_utils.pyx to hdbscan\\_prediction_utils.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-tofc60h5\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-24imy99a\\hdbscan_3aafd7b966b249cebac649891ae8a9dc\\hdbscan\\_prediction_utils.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  cythoning hdbscan/dist_metrics.pyx to hdbscan\\dist_metrics.c\n",
      "  C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-build-env-tofc60h5\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\ehsan.estaji\\AppData\\Local\\Temp\\pip-install-24imy99a\\hdbscan_3aafd7b966b249cebac649891ae8a9dc\\hdbscan\\dist_metrics.pxd\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  building 'hdbscan._hdbscan_tree' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for hdbscan\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [454 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\n",
      "  copying gensim\\downloader.py -> build\\lib.win-amd64-3.9\\gensim\n",
      "  copying gensim\\interfaces.py -> build\\lib.win-amd64-3.9\\gensim\n",
      "  copying gensim\\matutils.py -> build\\lib.win-amd64-3.9\\gensim\n",
      "  copying gensim\\nosy.py -> build\\lib.win-amd64-3.9\\gensim\n",
      "  copying gensim\\utils.py -> build\\lib.win-amd64-3.9\\gensim\n",
      "  copying gensim\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\bleicorpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\csvcorpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\dictionary.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\hashdictionary.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\indexedcorpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\lowcorpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\malletcorpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\mmcorpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\sharded_corpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\svmlightcorpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\textcorpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\ucicorpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\wikicorpus.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\corpora\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\atmodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\basemodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\base_any2vec.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\callbacks.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\coherencemodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\doc2vec.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\fasttext.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\hdpmodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\keyedvectors.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\ldamodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\ldamulticore.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\ldaseqmodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\lda_dispatcher.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\lda_worker.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\logentropy_model.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\lsimodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\lsi_dispatcher.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\lsi_worker.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\nmf.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\normmodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\phrases.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\poincare.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\rpmodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\tfidfmodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\translation_matrix.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\utils_any2vec.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\word2vec.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\_fasttext_bin.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\parsing\n",
      "  copying gensim\\parsing\\porter.py -> build\\lib.win-amd64-3.9\\gensim\\parsing\n",
      "  copying gensim\\parsing\\preprocessing.py -> build\\lib.win-amd64-3.9\\gensim\\parsing\n",
      "  copying gensim\\parsing\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\parsing\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\glove2word2vec.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\make_wiki.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\make_wikicorpus.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\make_wiki_lemma.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\make_wiki_online.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\make_wiki_online_lemma.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\make_wiki_online_nodebug.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\package_info.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\segment_wiki.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\word2vec2tensor.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\word2vec_standalone.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  copying gensim\\scripts\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\scripts\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\similarities\n",
      "  copying gensim\\similarities\\docsim.py -> build\\lib.win-amd64-3.9\\gensim\\similarities\n",
      "  copying gensim\\similarities\\index.py -> build\\lib.win-amd64-3.9\\gensim\\similarities\n",
      "  copying gensim\\similarities\\levenshtein.py -> build\\lib.win-amd64-3.9\\gensim\\similarities\n",
      "  copying gensim\\similarities\\nmslib.py -> build\\lib.win-amd64-3.9\\gensim\\similarities\n",
      "  copying gensim\\similarities\\termsim.py -> build\\lib.win-amd64-3.9\\gensim\\similarities\n",
      "  copying gensim\\similarities\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\similarities\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\atmodel.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\d2vmodel.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\ftmodel.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\hdp.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\ldamodel.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\ldaseqmodel.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\lsimodel.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\phrases.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\rpmodel.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\text2bow.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\tfidf.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\w2vmodel.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  copying gensim\\sklearn_api\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\sklearn_api\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  copying gensim\\summarization\\bm25.py -> build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  copying gensim\\summarization\\commons.py -> build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  copying gensim\\summarization\\graph.py -> build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  copying gensim\\summarization\\keywords.py -> build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  copying gensim\\summarization\\mz_entropy.py -> build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  copying gensim\\summarization\\pagerank_weighted.py -> build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  copying gensim\\summarization\\summarizer.py -> build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  copying gensim\\summarization\\syntactic_unit.py -> build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  copying gensim\\summarization\\textcleaner.py -> build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  copying gensim\\summarization\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\summarization\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\basetmtests.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\simspeed.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\simspeed2.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\svd_error.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_aggregation.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_api.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_atmodel.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_big.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_BM25.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_coherencemodel.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_corpora.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_corpora_dictionary.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_corpora_hashdictionary.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_d2vmodel.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_datatype.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_direct_confirmation.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_doc2vec.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_dtm.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_fasttext.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_fasttext_wrapper.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_glove2word2vec.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_hdpmodel.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_indirect_confirmation.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_keras_integration.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_keyedvectors.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_keywords.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_ldamallet_wrapper.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_ldamodel.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_ldaseqmodel.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_ldavowpalwabbit_wrapper.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_lda_callback.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_lee.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_logentropy_model.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_lsimodel.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_matutils.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_miislita.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_nmf.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_normmodel.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_parsing.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_phrases.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_poincare.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_probability_estimation.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_rpmodel.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_scripts.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_segmentation.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_sharded_corpus.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_similarities.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_similarity_metrics.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_sklearn_api.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_summarization.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_text_analysis.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_tfidfmodel.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_tmdiff.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_translation_matrix.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_utils.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_utils_any2vec.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_varembed_wrapper.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_word2vec.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\test_wordrank_wrapper.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\utils.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  copying gensim\\test\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\test\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\topic_coherence\n",
      "  copying gensim\\topic_coherence\\aggregation.py -> build\\lib.win-amd64-3.9\\gensim\\topic_coherence\n",
      "  copying gensim\\topic_coherence\\direct_confirmation_measure.py -> build\\lib.win-amd64-3.9\\gensim\\topic_coherence\n",
      "  copying gensim\\topic_coherence\\indirect_confirmation_measure.py -> build\\lib.win-amd64-3.9\\gensim\\topic_coherence\n",
      "  copying gensim\\topic_coherence\\probability_estimation.py -> build\\lib.win-amd64-3.9\\gensim\\topic_coherence\n",
      "  copying gensim\\topic_coherence\\segmentation.py -> build\\lib.win-amd64-3.9\\gensim\\topic_coherence\n",
      "  copying gensim\\topic_coherence\\text_analysis.py -> build\\lib.win-amd64-3.9\\gensim\\topic_coherence\n",
      "  copying gensim\\topic_coherence\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\topic_coherence\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\viz\n",
      "  copying gensim\\viz\\poincare.py -> build\\lib.win-amd64-3.9\\gensim\\viz\n",
      "  copying gensim\\viz\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\viz\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\models\\deprecated\n",
      "  copying gensim\\models\\deprecated\\doc2vec.py -> build\\lib.win-amd64-3.9\\gensim\\models\\deprecated\n",
      "  copying gensim\\models\\deprecated\\fasttext.py -> build\\lib.win-amd64-3.9\\gensim\\models\\deprecated\n",
      "  copying gensim\\models\\deprecated\\fasttext_wrapper.py -> build\\lib.win-amd64-3.9\\gensim\\models\\deprecated\n",
      "  copying gensim\\models\\deprecated\\keyedvectors.py -> build\\lib.win-amd64-3.9\\gensim\\models\\deprecated\n",
      "  copying gensim\\models\\deprecated\\old_saveload.py -> build\\lib.win-amd64-3.9\\gensim\\models\\deprecated\n",
      "  copying gensim\\models\\deprecated\\word2vec.py -> build\\lib.win-amd64-3.9\\gensim\\models\\deprecated\n",
      "  copying gensim\\models\\deprecated\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\models\\deprecated\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\models\\wrappers\n",
      "  copying gensim\\models\\wrappers\\dtmmodel.py -> build\\lib.win-amd64-3.9\\gensim\\models\\wrappers\n",
      "  copying gensim\\models\\wrappers\\fasttext.py -> build\\lib.win-amd64-3.9\\gensim\\models\\wrappers\n",
      "  copying gensim\\models\\wrappers\\ldamallet.py -> build\\lib.win-amd64-3.9\\gensim\\models\\wrappers\n",
      "  copying gensim\\models\\wrappers\\ldavowpalwabbit.py -> build\\lib.win-amd64-3.9\\gensim\\models\\wrappers\n",
      "  copying gensim\\models\\wrappers\\varembed.py -> build\\lib.win-amd64-3.9\\gensim\\models\\wrappers\n",
      "  copying gensim\\models\\wrappers\\wordrank.py -> build\\lib.win-amd64-3.9\\gensim\\models\\wrappers\n",
      "  copying gensim\\models\\wrappers\\__init__.py -> build\\lib.win-amd64-3.9\\gensim\\models\\wrappers\n",
      "  running egg_info\n",
      "  writing gensim.egg-info\\PKG-INFO\n",
      "  writing dependency_links to gensim.egg-info\\dependency_links.txt\n",
      "  writing requirements to gensim.egg-info\\requires.txt\n",
      "  writing top-level names to gensim.egg-info\\top_level.txt\n",
      "  reading manifest file 'gensim.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching 'COPYING.LESSER'\n",
      "  warning: no files found matching 'ez_setup.py'\n",
      "  warning: no files found matching 'gensim\\models\\doc2vec_inner.c'\n",
      "  adding license file 'COPYING'\n",
      "  writing manifest file 'gensim.egg-info\\SOURCES.txt'\n",
      "  copying gensim\\_matutils.c -> build\\lib.win-amd64-3.9\\gensim\n",
      "  copying gensim\\_matutils.pyx -> build\\lib.win-amd64-3.9\\gensim\n",
      "  copying gensim\\corpora\\_mmreader.c -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\models\\_utils_any2vec.c -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\doc2vec_corpusfile.cpp -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\doc2vec_inner.cpp -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\fasttext_corpusfile.cpp -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\fasttext_inner.c -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\nmf_pgd.c -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\word2vec_corpusfile.cpp -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\word2vec_inner.c -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\corpora\\_mmreader.pyx -> build\\lib.win-amd64-3.9\\gensim\\corpora\n",
      "  copying gensim\\models\\_utils_any2vec.pyx -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\doc2vec_corpusfile.pyx -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\doc2vec_inner.pxd -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\doc2vec_inner.pyx -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\fast_line_sentence.h -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\fasttext_corpusfile.pyx -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\fasttext_inner.pxd -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\fasttext_inner.pyx -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\nmf_pgd.pyx -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\stdint_wrapper.h -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\voidptr.h -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\word2vec_corpusfile.pxd -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\word2vec_corpusfile.pyx -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\word2vec_inner.pxd -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  copying gensim\\models\\word2vec_inner.pyx -> build\\lib.win-amd64-3.9\\gensim\\models\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\EN.1-10.cbow1_wind5_hs0_neg10_size300_smpl1e-05.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\IT.1-10.cbow1_wind5_hs0_neg10_size300_smpl1e-05.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\OPUS_en_it_europarl_train_one2ten.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\alldata-id-10.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\atmodel_3_0_1_model -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\atmodel_3_0_1_model.expElogbeta.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\atmodel_3_0_1_model.id2word -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\atmodel_3_0_1_model.state -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\bgwiki-latest-pages-articles-shortened.xml.bz2 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\compatible-hash-false.model -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\compatible-hash-true.model -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\cp852_fasttext.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\crime-and-punishment.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\crime-and-punishment.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\crime-and-punishment.vec -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\d2v-lee-v0.13.0 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\doc2vec_old -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\doc2vec_old_sep -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\doc2vec_old_sep.syn0_lockf.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\doc2vec_old_sep.syn1neg.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\dtm_test.dict -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\dtm_test.mm -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\enwiki-table-markup.xml.bz2 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\euclidean_vectors.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\fasttext_old -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\fasttext_old_sep -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\fasttext_old_sep.syn0_lockf.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\fasttext_old_sep.syn1neg.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\fb-ngrams.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ft_kv_3.6.0.model.gz -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ft_model_2.3.0 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\head500.noblanks.cor -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\head500.noblanks.cor.bz2 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\head500.noblanks.cor_tfidf.model -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\head500.noblanks.cor_wordids.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\high_precision.kv.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\high_precision.kv.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\large_tag_doc_10_iter50 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\lda_3_0_1_model -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\lda_3_0_1_model.expElogbeta.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\lda_3_0_1_model.id2word -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\lda_3_0_1_model.state -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ldamodel_python_2_7 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ldamodel_python_2_7.expElogbeta.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ldamodel_python_2_7.id2word -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ldamodel_python_2_7.state -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ldamodel_python_3_5 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ldamodel_python_3_5.expElogbeta.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ldamodel_python_3_5.id2word -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ldamodel_python_3_5.state -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ldavowpalwabbit.dict.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\ldavowpalwabbit.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\lee.cor -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\lee_background.cor -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\lee_fasttext -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\lee_fasttext.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\lee_fasttext.vec -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\lee_fasttext_new.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\miIslita.cor -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\mihalcea_tarau.kw.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\mihalcea_tarau.kwpos.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\mihalcea_tarau.summ.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\mihalcea_tarau.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\mini_newsgroup -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\nmf_model -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\non_ascii_fasttext.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\old_keyedvectors_320.dat -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\pang_lee_polarity.cor -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\pang_lee_polarity_fasttext.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\pang_lee_polarity_fasttext.vec -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\para2para_text1.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\para2para_text2.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\phraser-3.6.0.model -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\phraser-no-common-terms.pkl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\phraser-no-scoring.pkl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\phraser-scoring-str.pkl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\phrases-3.6.0.model -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\phrases-no-common-terms.pkl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\phrases-no-scoring.pkl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\phrases-scoring-str.pkl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\phrases-transformer-new-v3-5-0.pkl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\phrases-transformer-v3-5-0.pkl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\poincare_cp852.tsv -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\poincare_hypernyms.tsv -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\poincare_hypernyms_large.tsv -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\poincare_test_3.4.0 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\poincare_utf8.tsv -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\poincare_vectors.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\pre_0_13_2_model -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\pre_0_13_2_model.state -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\pretrained.vec -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\questions-words.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\reproduce.dat -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\reproduce.dat.gz -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\similarities0-1.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\simlex999.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\small_tag_doc_5_iter50 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\test_corpus_ok.mm -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\test_corpus_small.mm -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\test_glove.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\test_mmcorpus_corrupt.mm -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\test_mmcorpus_no_index.mm -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\test_mmcorpus_no_index.mm.bz2 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\test_mmcorpus_no_index.mm.gz -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\test_mmcorpus_overflow.mm -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\test_mmcorpus_with_index.mm -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\test_mmcorpus_with_index.mm.index -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.blei -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.blei.index -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.blei.vocab -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.low -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.low.index -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.mallet -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.mallet.index -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.mm -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.mm.index -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.svmlight -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.svmlight.index -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.uci -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.uci.index -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.uci.vocab -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus.xml.bz2 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testcorpus_serialization.mm.index -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testlowdistinctwords.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testrepeatedkeywords.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\testsummarization_unrelated.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\tfidf_model.tst -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\tfidf_model.tst.bz2 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\tfidf_model_3_2.tst -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\toy-data.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\toy-model-pretrained.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\toy-model.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\toy-model.vec -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\varembed_lee_subcorpus.cor -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\varembed_morfessor.bin -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\varembed_vectors.pkl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\w2v-lee-v0.12.0 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\w2v_keyedvectors_load_test.modeldata -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\w2v_keyedvectors_load_test.vocab -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_3.3 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_old -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_old_sep -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_old_sep.syn0_lockf.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_old_sep.syn1neg.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_c -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_py2 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_py3 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_py3_4 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py2 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py2.neg_labels.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py2.syn0.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py2.syn0_lockf.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py2.syn1neg.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py3 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py3.neg_labels.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py3.syn0.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py3.syn0_lockf.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py3.syn1neg.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py3_4 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py3_4.neg_labels.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py3_4.syn0.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py3_4.syn0_lockf.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\word2vec_pre_kv_sep_py3_4.syn1neg.npy -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  copying gensim\\test\\test_data\\wordsim353.tsv -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\DTM\n",
      "  copying gensim\\test\\test_data\\DTM\\ldaseq_3_0_1_model -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\DTM\n",
      "  copying gensim\\test\\test_data\\DTM\\sstats_test.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\DTM\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\PathLineSentences\n",
      "  copying gensim\\test\\test_data\\PathLineSentences\\1.txt -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\PathLineSentences\n",
      "  copying gensim\\test\\test_data\\PathLineSentences\\2.txt.bz2 -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\PathLineSentences\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_0.12.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_0.12.1.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_0.12.2.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_0.12.3.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_0.12.4.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_0.13.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_0.13.1.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_0.13.2.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_0.13.3.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_0.13.4.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_1.0.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_1.0.1.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_2.0.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_2.1.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_2.2.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_2.3.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_3.0.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_3.1.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_3.2.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_3.3.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  copying gensim\\test\\test_data\\old_d2v_models\\d2v_3.4.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_d2v_models\n",
      "  creating build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_0.12.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_0.12.1.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_0.12.2.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_0.12.3.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_0.12.4.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_0.13.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_0.13.1.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_0.13.2.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_0.13.3.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_0.13.4.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_1.0.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_1.0.1.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_2.0.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_2.1.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_2.2.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_2.3.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_3.0.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_3.1.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_3.2.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_3.3.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  copying gensim\\test\\test_data\\old_w2v_models\\w2v_3.4.0.mdl -> build\\lib.win-amd64-3.9\\gensim\\test\\test_data\\old_w2v_models\n",
      "  running build_ext\n",
      "  building 'gensim.models.word2vec_inner' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for gensim\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [11 lines of output]\n",
      "  C:\\Users\\ehsan.estaji\\Anaconda3\\lib\\site-packages\\setuptools\\dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  copying sentencepiece.py -> build\\lib.win-amd64-3.9\n",
      "  running build_ext\n",
      "  building '_sentencepiece' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for sentencepiece\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [47 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\n",
      "  copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\models\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\decoders\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\normalizers\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\pre_tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\processors\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\trainers\n",
      "  creating build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-39\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\n",
      "  copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\tokenizers\\trainers\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for hdbscan, tokenizers, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic[flair]) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic[flair]) (1.20.3)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic[flair]) (4.62.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic[flair]) (0.24.2)\n",
      "Collecting hdbscan>=0.8.28\n",
      "  Using cached hdbscan-0.8.28.tar.gz (5.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic[flair]) (2.2.0)\n",
      "Requirement already satisfied: plotly>=4.7.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic[flair]) (5.6.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic[flair]) (1.3.4)\n",
      "Collecting pyyaml<6.0\n",
      "  Using cached PyYAML-5.4.1-cp39-cp39-win_amd64.whl (213 kB)\n",
      "Collecting flair==0.7\n",
      "  Downloading flair-0.7-py3-none-any.whl (448 kB)\n",
      "     -------------------------------------- 448.3/448.3 KB 5.6 MB/s eta 0:00:00\n",
      "Collecting transformers==3.5.1\n",
      "  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 9.2 MB/s eta 0:00:00\n",
      "Collecting bertopic[flair]\n",
      "  Downloading bertopic-0.9.4-py2.py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.6/57.6 KB 3.0 MB/s eta 0:00:00\n",
      "  Downloading bertopic-0.9.3-py2.py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.1/57.1 KB ? eta 0:00:00\n",
      "Collecting plotly<4.14.3,>=4.7.0\n",
      "  Downloading plotly-4.14.2-py2.py3-none-any.whl (13.2 MB)\n",
      "     --------------------------------------- 13.2/13.2 MB 12.6 MB/s eta 0:00:00\n",
      "Collecting bertopic[flair]\n",
      "  Downloading bertopic-0.9.2-py2.py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.1/57.1 KB 2.9 MB/s eta 0:00:00\n",
      "  Downloading bertopic-0.9.1-py2.py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.9/55.9 KB 2.9 MB/s eta 0:00:00\n",
      "  Downloading bertopic-0.9.0-py2.py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.9/55.9 KB ? eta 0:00:00\n",
      "  Downloading bertopic-0.8.1-py2.py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.8/53.8 KB ? eta 0:00:00\n",
      "  Downloading bertopic-0.8.0-py2.py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.2/53.2 KB 2.7 MB/s eta 0:00:00\n",
      "  Downloading bertopic-0.7.0-py2.py3-none-any.whl (40 kB)\n",
      "     ---------------------------------------- 40.8/40.8 KB ? eta 0:00:00\n",
      "  Downloading bertopic-0.6.0-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bertopic[flair]) (1.11.0)\n",
      "Requirement already satisfied: regex in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from flair==0.7->bertopic[flair]) (2021.8.3)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from flair==0.7->bertopic[flair]) (4.6.3)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from flair==0.7->bertopic[flair]) (1.2.13)\n",
      "Collecting konoha<5.0.0,>=4.0.0\n",
      "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
      "Collecting sentencepiece<=0.1.91\n",
      "  Downloading sentencepiece-0.1.91.tar.gz (500 kB)\n",
      "     ------------------------------------- 500.5/500.5 KB 15.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting bpemb>=0.3.2\n",
      "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
      "Collecting janome\n",
      "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
      "     ---------------------------------------- 19.7/19.7 MB 8.6 MB/s eta 0:00:00\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
      "     ---------------------------------------- 46.3/46.3 KB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "     ------------------------------------- 788.5/788.5 KB 16.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gensim<=3.8.3,>=3.4.0\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "     --------------------------------------- 23.4/23.4 MB 10.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting hyperopt>=0.1.1\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 12.6 MB/s eta 0:00:00\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.1/53.1 KB ? eta 0:00:00\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ------------------------------------- 981.5/981.5 KB 15.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from flair==0.7->bertopic[flair]) (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from flair==0.7->bertopic[flair]) (2.8.2)\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.28->bertopic[flair]) (1.7.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.28->bertopic[flair]) (1.1.0)\n",
      "Requirement already satisfied: cython>=0.27 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.28->bertopic[flair]) (0.29.24)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from pandas>=1.1.5->bertopic[flair]) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2.post1->bertopic[flair]) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[flair]) (0.5.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[flair]) (3.6.5)\n",
      "Collecting sentence-transformers>=0.4.1\n",
      "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 KB 4.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading sentence-transformers-2.0.0.tar.gz (85 kB)\n",
      "     ---------------------------------------- 85.5/85.5 KB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading sentence-transformers-1.2.1.tar.gz (80 kB)\n",
      "     ---------------------------------------- 80.8/80.8 KB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: torchvision in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic[flair]) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from torch>=1.4.0->bertopic[flair]) (3.10.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from tqdm>=4.41.1->bertopic[flair]) (0.4.4)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from umap-learn>=0.5.0->bertopic[flair]) (0.54.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from umap-learn>=0.5.0->bertopic[flair]) (0.5.6)\n",
      "Requirement already satisfied: requests in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from bpemb>=0.3.2->flair==0.7->bertopic[flair]) (2.27.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from deprecated>=1.2.4->flair==0.7->bertopic[flair]) (1.12.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from gensim<=3.8.3,>=3.4.0->flair==0.7->bertopic[flair]) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from gensim<=3.8.3,>=3.4.0->flair==0.7->bertopic[flair]) (5.2.1)\n",
      "Requirement already satisfied: future in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair==0.7->bertopic[flair]) (0.18.2)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "     ------------------------------------- 199.7/199.7 KB 12.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair==0.7->bertopic[flair]) (2.0.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair==0.7->bertopic[flair]) (2.6.3)\n",
      "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Collecting overrides<4.0.0,>=3.0.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair==0.7->bertopic[flair]) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair==0.7->bertopic[flair]) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair==0.7->bertopic[flair]) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair==0.7->bertopic[flair]) (1.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic[flair]) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic[flair]) (0.37.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers==3.5.1->bertopic[flair]) (3.3.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers==3.5.1->bertopic[flair]) (0.0.49)\n",
      "Requirement already satisfied: packaging in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers==3.5.1->bertopic[flair]) (21.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from transformers==3.5.1->bertopic[flair]) (3.19.4)\n",
      "Collecting tokenizers==0.9.3\n",
      "  Downloading tokenizers-0.9.3.tar.gz (172 kB)\n",
      "     ---------------------------------------- 172.0/172.0 KB ? eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from ftfy->flair==0.7->bertopic[flair]) (0.2.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from gdown->flair==0.7->bertopic[flair]) (4.10.0)\n",
      "Requirement already satisfied: click in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers>=0.4.1->bertopic[flair]) (8.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair==0.7->bertopic[flair]) (3.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair==0.7->bertopic[flair]) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair==0.7->bertopic[flair]) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair==0.7->bertopic[flair]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair==0.7->bertopic[flair]) (2021.10.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown->flair==0.7->bertopic[flair]) (2.2.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\ehsan.estaji\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair==0.7->bertopic[flair]) (1.7.1)\n",
      "Building wheels for collected packages: mpld3, hdbscan, sentence-transformers, gensim, sentencepiece, sqlitedict, tokenizers, gdown, langdetect, overrides\n",
      "  Building wheel for mpld3 (setup.py): started\n",
      "  Building wheel for mpld3 (setup.py): finished with status 'done'\n",
      "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=a9ed4f67b263862027996ef34a4b9a99f93ff9b792c9f65a7aed886600924037\n",
      "  Stored in directory: c:\\users\\ehsan.estaji\\appdata\\local\\pip\\cache\\wheels\\a6\\f4\\e6\\e40ff9021f6b3854af70fa8ea004f5ab95672817462df08fed\n",
      "  Building wheel for hdbscan (pyproject.toml): started\n",
      "  Building wheel for hdbscan (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-1.2.1-py3-none-any.whl size=123300 sha256=f61217130edb499b7e74a4a8c46a749241ac6c186e4739ed0afe84d4007caad3\n",
      "  Stored in directory: c:\\users\\ehsan.estaji\\appdata\\local\\pip\\cache\\wheels\\7d\\89\\99\\3ad94aa1a3101366137dabb0585fdac8339b3cdcee2108da82\n",
      "  Building wheel for gensim (setup.py): started\n",
      "  Building wheel for gensim (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for gensim\n",
      "  Building wheel for sentencepiece (setup.py): started\n",
      "  Building wheel for sentencepiece (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for sentencepiece\n",
      "  Building wheel for sqlitedict (setup.py): started\n",
      "  Building wheel for sqlitedict (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=b6c0245c3b0826d2db164261005316540c1947c6470843332947330b955b436b\n",
      "  Stored in directory: c:\\users\\ehsan.estaji\\appdata\\local\\pip\\cache\\wheels\\48\\a5\\80\\fa89dc26af0f4c280b500f5529978552379c1ce8907e0a281c\n",
      "  Building wheel for tokenizers (pyproject.toml): started\n",
      "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for gdown (pyproject.toml): started\n",
      "  Building wheel for gdown (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14775 sha256=720414622b0e8f1d7afd9a887442cc982f880ede9df2d0cdc9686df410a8cbbe\n",
      "  Stored in directory: c:\\users\\ehsan.estaji\\appdata\\local\\pip\\cache\\wheels\\7d\\37\\b6\\b2a79c75e898c0b8e46ff255102602d7159a10d9af0d80641a\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=ca424bfdf0e926609c60036d5d3b56e9152c294507e8d6ec305956d88f685daf\n",
      "  Stored in directory: c:\\users\\ehsan.estaji\\appdata\\local\\pip\\cache\\wheels\\d1\\c1\\d9\\7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "  Building wheel for overrides (setup.py): started\n",
      "  Building wheel for overrides (setup.py): finished with status 'done'\n",
      "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10186 sha256=a5212c42af0d813ba95cf42caad774e4be39a7afb5262f695f1962d8f07a591e\n",
      "  Stored in directory: c:\\users\\ehsan.estaji\\appdata\\local\\pip\\cache\\wheels\\7d\\11\\0e\\73fdcb3d71d97e33c230900efe85923ee9d49515d050503174\n",
      "Successfully built mpld3 sentence-transformers sqlitedict gdown langdetect overrides\n",
      "Failed to build hdbscan gensim sentencepiece tokenizers\n"
     ]
    }
   ],
   "source": [
    "pip install bertopic[flair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de93d89c-57f6-446f-b220-f7d758afa5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

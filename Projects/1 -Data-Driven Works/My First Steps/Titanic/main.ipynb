{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b98864-fa7a-428c-b351-4c64ffd9662e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 12), (891,), (418, 12))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# Importing the dataset\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "combine= [df_train, df_test]\n",
    "#print(df_train.columns.values)\n",
    "#print(df_train.info())\n",
    "#print('_' * 40)\n",
    "#print(df_test.info())\n",
    "#df_train.describe(include='O', exclude='category')\n",
    "\n",
    "\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.drop([col for col in dataset if dataset[col].count()/len(dataset) <= 0.3 ]+['PassengerId'], axis =1, inplace = True )\n",
    "    \n",
    "    \n",
    "for dataset in combine:\n",
    "    dataset.drop('Ticket', axis = 1, inplace = True)\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "guess_ages = np.zeros((2,3))\n",
    "guess_ages\n",
    "for dataset in combine:\n",
    "    for i in range(0,2):\n",
    "        for j in range(0,3):\n",
    "            guess_ages[i,j] = df_train[(df_train['Sex'] == i) & (df_train['Pclass'] == j+1)].dropna()['Age'].median()\n",
    "    for i in range(0,2):\n",
    "        for j in range(0,3):\n",
    "            dataset.loc[(dataset.Age.isnull() & (dataset.Sex == i) & (dataset.Pclass == j+1)),'Age'] = guess_ages[i,j]\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "df_train.Embarked.value_counts().idxmax()\n",
    "df_train.Embarked.fillna(df_train.Embarked.value_counts().idxmax(), inplace= True)\n",
    "df_train.isna().sum()\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imr = SimpleImputer(missing_values= np.NaN, strategy='mean')\n",
    "imr = imr.fit(df_test[['Fare']])\n",
    "df_test['Fare'] = imr.transform(df_test[['Fare']]).ravel()\n",
    "\n",
    "for dataset in combine: \n",
    "    dataset['FamilySize'] = dataset.SibSp + dataset.Parch + 1\n",
    "    dataset.drop(columns=['SibSp','Parch'], inplace = True)\n",
    "    \n",
    "    \n",
    "for dataset in combine: \n",
    "    dataset.Embarked = dataset.Embarked.map({'S':0,'Q':1,'C':2}).astype(int)\n",
    "    \n",
    "    \n",
    "df_train['AgeBand'] = pd.cut(df_train.Age, bins= 5)\n",
    "df_train.AgeBand.value_counts()\n",
    "\n",
    "\n",
    "for dataset in combine: \n",
    "    dataset.loc[(dataset.Age <= 16) , 'Age'] = 0\n",
    "    dataset.loc[(dataset.Age > 16) & (dataset.Age <= 32), 'Age'] = 1 \n",
    "    dataset.loc[(dataset.Age > 32) & (dataset.Age <= 48), 'Age'] = 2 \n",
    "    dataset.loc[(dataset.Age > 48) & (dataset.Age <= 64), 'Age'] = 3 \n",
    "    dataset.loc[(dataset.Age > 64) & (dataset.Age <= 80), 'Age'] = 4 \n",
    "df_train.drop(columns='AgeBand', inplace= True)\n",
    "    \n",
    "    \n",
    "    \n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset.FamilySize == 1,'IsAlone'] = 1\n",
    "    dataset.drop(columns= 'FamilySize', inplace = True)\n",
    "    \n",
    "    \n",
    "df_test.Fare.fillna(df_test.Fare.dropna().median(), inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "df_train['FareBand'] = pd.cut(df_train.Fare, bins = 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "df_train = df_train.drop(['FareBand'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_train['Title'] = df_train['Name'].str.extract(' ([A-Za-z]+)\\.', expand= False)\n",
    "df_test['Title'] = df_test['Name'].str.extract(' ([A-Za-z]+)\\.', expand= False)\n",
    "df_train.drop('Name', axis = 1 , inplace = True)\n",
    "df_test.drop('Name', axis = 1 , inplace = True )\n",
    "combine = [df_train, df_test]\n",
    "\n",
    "\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "\n",
    "    \n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [2])], remainder='passthrough')\n",
    "new = df_train.columns.to_list()\n",
    "new.remove('Sex')\n",
    "new_col = ['Female', 'Male'] + new\n",
    "df_train = pd.DataFrame(np.array(columnTransformer.fit_transform(df_train)), columns= new_col)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
    "new = df_train.columns.to_list()\n",
    "new.remove('Pclass')\n",
    "new_col = ['First Class', 'Second Class', 'Third Class'] + new\n",
    "df_train = pd.DataFrame(np.array(columnTransformer.fit_transform(df_train)), columns= new_col)\n",
    "\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [8])], remainder='passthrough')\n",
    "new = df_train.columns.to_list()\n",
    "new.remove('Embarked')\n",
    "new_col = ['Emb C', 'Emb Q', 'Emb S'] + new\n",
    "df_train = pd.DataFrame(np.array(columnTransformer.fit_transform(df_train)), columns= new_col)\n",
    "\n",
    "\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "new = df_test.columns.to_list()\n",
    "new.remove('Sex')\n",
    "new_col = ['Female', 'Male'] + new\n",
    "df_test = pd.DataFrame(np.array(columnTransformer.fit_transform(df_test)), columns= new_col)\n",
    "\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [2])], remainder='passthrough')\n",
    "new = df_test.columns.to_list()\n",
    "new.remove('Pclass')\n",
    "new_col = ['First Class', 'Second Class', 'Third Class'] + new\n",
    "df_test = pd.DataFrame(np.array(columnTransformer.fit_transform(df_test)), columns= new_col)\n",
    "\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [7])], remainder='passthrough')\n",
    "new = df_test.columns.to_list()\n",
    "new.remove('Embarked')\n",
    "new_col = ['Emb C', 'Emb Q', 'Emb S'] + new\n",
    "df_test = pd.DataFrame(np.array(columnTransformer.fit_transform(df_test)), columns= new_col)\n",
    "\n",
    "\n",
    "\n",
    "X_train = df_train.drop(\"Survived\", axis=1)\n",
    "Y_train = df_train[\"Survived\"]\n",
    "X_test  = df_test.copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b040e-93a6-4964-8a5a-4eacf21f1c40",
   "metadata": {},
   "source": [
    "# Model, Predict and Solve ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395d5854-9030-4bd0-b0dc-fe3952318b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "# note that the test set using the fitted scaler in train dataset to transform in the test set\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48cbe8a2-cdfd-4b45-a7c8-ddde867ca42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization with sklearn\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "#norm = MinMaxScaler().fit(X_train_scaled)\n",
    "\n",
    "# transform training data\n",
    "#X_train_norm = norm.transform(X_train_scaled)\n",
    "\n",
    "# transform testing dataabs\n",
    "#X_test_norm = norm.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6267f8d-d1a8-4ff2-bda4-1cd2728a7403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>81.594257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>81.480649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>80.700375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>80.581773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>80.471910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>79.352060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>79.235955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>77.776529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>73.176030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>72.945069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model      Score\n",
       "1                     SVC  81.594257\n",
       "0           XGBClassifier  81.480649\n",
       "4      LogisticRegression  80.700375\n",
       "3  RandomForestClassifier  80.581773\n",
       "2  DecisionTreeClassifier  80.471910\n",
       "8               LinearSVC  79.352060\n",
       "5    KNeighborsClassifier  79.235955\n",
       "6              GaussianNB  77.776529\n",
       "9           SGDClassifier  73.176030\n",
       "7              Perceptron  72.945069"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers = []\n",
    "model1 = xgboost.XGBClassifier(eval_metric='mlogloss')\n",
    "classifiers.append(model1)\n",
    "\n",
    "\n",
    "model2 = svm.SVC(C = 5)\n",
    "classifiers.append(model2)\n",
    "\n",
    "\n",
    "model3 = tree.DecisionTreeClassifier(criterion= 'entropy', splitter='best')\n",
    "classifiers.append(model3)\n",
    "\n",
    "\n",
    "model4 = RandomForestClassifier(criterion='entropy')\n",
    "classifiers.append(model4)\n",
    "\n",
    "model5 = LogisticRegression()\n",
    "classifiers.append(model5)\n",
    "\n",
    "model6 =KNeighborsClassifier(n_neighbors = 4)\n",
    "classifiers.append(model6)\n",
    "\n",
    "\n",
    "model7 = GaussianNB()\n",
    "classifiers.append(model7)\n",
    "\n",
    "\n",
    "model8 = Perceptron()\n",
    "classifiers.append(model8)\n",
    "\n",
    "\n",
    "model9 = LinearSVC()\n",
    "classifiers.append(model9)\n",
    "\n",
    "model10 = SGDClassifier()\n",
    "classifiers.append(model10)\n",
    "\n",
    "ModelName = [type(classifiers[i]).__name__ for i in range(0,10)]\n",
    "\n",
    "Model_Score = []\n",
    "for clf in classifiers:\n",
    "    kfold = KFold(n_splits=10, random_state= 0, shuffle= True)\n",
    "    Model_Score.append(cross_val_score(clf, X_train, Y_train, cv=kfold).mean()*100.0)\n",
    "ModelDF = pd.DataFrame({'Model' : ModelName, 'Score' : pd.Series(Model_Score)})\n",
    "ModelDF.sort_values(by = 'Score', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea94fe6-a6de-4c84-9085-27f12a96a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred= clf.predict(X_test)\n",
    "Y_pred\n",
    "Y_pred = Y_pred.astype('int')\n",
    "submit = pd.read_csv('gender_submission.csv')\n",
    "submit['Survived'] = pd.Series(Y_pred)\n",
    "submit.to_csv('KaggleTitanicSubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac6027e-22a2-4c57-9103-776baba50f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

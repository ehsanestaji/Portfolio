{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "72b98864-fa7a-428c-b351-4c64ffd9662e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>81.710362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>81.706617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>80.808989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>80.021223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>79.574282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>79.570537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>79.235955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>77.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>75.534332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>72.835206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model      Score\n",
       "0           XGBClassifier  81.710362\n",
       "1                     SVC  81.706617\n",
       "3  RandomForestClassifier  80.808989\n",
       "4      LogisticRegression  80.021223\n",
       "8               LinearSVC  79.574282\n",
       "6              GaussianNB  79.570537\n",
       "5    KNeighborsClassifier  79.235955\n",
       "2  DecisionTreeClassifier  77.888889\n",
       "9           SGDClassifier  75.534332\n",
       "7              Perceptron  72.835206"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "\n",
    "   \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "# Importing the dataset\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "combine= [df_train, df_test]\n",
    "te\n",
    "for dataset in combine:\n",
    "    imr = SimpleImputer(missing_values= np.NaN, strategy='mean')\n",
    "    imr = imr.fit(dataset[['Age']])\n",
    "    dataset['Age'] = imr.transform(dataset[['Age']]).ravel()\n",
    "\n",
    "\n",
    "\n",
    "imr = SimpleImputer(missing_values= np.NaN, strategy='most_frequent')\n",
    "imr = imr.fit(df_train[['Embarked']])\n",
    "df_train['Embarked'] = imr.transform(df_train[['Embarked']]).ravel()\n",
    "\n",
    "\n",
    "\n",
    "imr = SimpleImputer(missing_values= np.NaN, strategy='mean')\n",
    "imr = imr.fit(df_test[['Fare']])\n",
    "df_test['Fare'] = imr.transform(df_test[['Fare']]).ravel()\n",
    "\n",
    "\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.drop(columns = ['Cabin','PassengerId', 'Name','Ticket'], axis = 1 , inplace = True )\n",
    "    \n",
    " \n",
    "\"\"\"\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [2])], remainder='passthrough')\n",
    "df_train_new = np.array(columnTransformer.fit_transform(df_train))\n",
    "list = df_train.columns.to_list()\n",
    "list.remove('Sex')\n",
    "df_train = pd.DataFrame(df_train_new, columns= ['Female', 'Male'] + list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "df_test_new = np.array(columnTransformer.fit_transform(df_test))\n",
    "list = df_test.columns.to_list()\n",
    "list.remove('Sex')\n",
    "df_test.columns.to_list().remove('Sex')\n",
    "df_test = pd.DataFrame(df_test_new, columns= ['Female', 'Male'] + list)\n",
    "\n",
    "\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
    "df_train_new = np.array(columnTransformer.fit_transform(df_train))\n",
    "list = df_train.columns.to_list()\n",
    "list.remove('Pclass')\n",
    "df_train = pd.DataFrame(df_train_new, columns= ['First Class', 'Second Class', 'Third Class'] + list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [2])], remainder='passthrough')\n",
    "df_test_new = np.array(columnTransformer.fit_transform(df_test))\n",
    "list = df_test.columns.to_list()\n",
    "list.remove('Pclass')\n",
    "df_test = pd.DataFrame(df_test_new, columns= ['First Class', 'Second Class', 'Third Class'] + list)\n",
    "\n",
    "\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [10])], remainder='passthrough')\n",
    "df_train_new = np.array(columnTransformer.fit_transform(df_train))\n",
    "list = df_train.columns.to_list()\n",
    "list.remove('Embarked')\n",
    "df_train = pd.DataFrame(df_train_new, columns= ['C Embarked', 'Q Embarked', 'S Embarked'] + list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [9])], remainder='passthrough')\n",
    "df_test_new = np.array(columnTransformer.fit_transform(df_test))\n",
    "list = df_test.columns.to_list()\n",
    "list.remove('Embarked')\n",
    "df_test = pd.DataFrame(df_test_new, columns= ['C Embarked', 'Q Embarked', 'S Embarked'] + list)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_train['Fare'] = np.round(df_train['Fare'].astype(float))\n",
    "df_train['Age'] = np.round(df_train['Age'].astype(float))\n",
    "\n",
    "df_test['Fare'] = np.round(df_test['Fare'].astype(float))\n",
    "df_test['Age'] = np.round(df_test['Age'].astype(float))\n",
    "\n",
    "\n",
    "Y_train = df_train[\"Survived\"].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "X_train = df_train\n",
    "X_test  = df_test\n",
    "X_train.shape, Y_train.shape, X_test.shape\n",
    "\n",
    "\n",
    "#df_train.drop('Survived', axis = 1, inplace = True)\n",
    "\n",
    "X_train['Family'] = X_train.SibSp + X_train.Parch\n",
    "X_train.drop(['SibSp', 'Parch'], axis = 1 , inplace = True )\n",
    "\n",
    "\n",
    "\n",
    "X_test['Family'] = X_test.SibSp + X_test.Parch\n",
    "X_test.drop(['SibSp', 'Parch'], axis = 1 , inplace = True )\n",
    "\n",
    "\n",
    "X_train.Sex = X_train.Sex.map({'male':0 , 'female':1})\n",
    "X_test.Sex = X_test.Sex.map({'male':0 , 'female':1})\n",
    "\n",
    "X_train.Embarked = X_train.Embarked.map({'C':0, 'Q': 1, 'S':2})\n",
    "X_test.Embarked = X_test.Embarked.map({'C':0, 'Q': 1, 'S':2})\n",
    "\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "scaler =StandardScaler()\n",
    "# scaler.fit(X_train.Age.values.reshape(-1,1))\n",
    "X_train.Age = pd.Series(scaler.fit_transform(X_train.Age.values.reshape(-1,1))[:,0])\n",
    "X_train.Fare = pd.Series(scaler.fit_transform(X_train.Fare.values.reshape(-1,1))[:,0])\n",
    "\n",
    "\n",
    "\n",
    "X_test.Age = pd.Series(scaler.fit_transform(X_test.Age.values.reshape(-1,1))[:,0])\n",
    "X_test.Fare = pd.Series(scaler.fit_transform(X_test.Fare.values.reshape(-1,1))[:,0])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train)\n",
    "new_column = df_train.columns.to_list()\n",
    "df_train=pd.DataFrame(scaler.transform(df_train), columns= new_column)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_test)\n",
    "new_column = df_test.columns.to_list()\n",
    "df_test = pd.DataFrame(scaler.transform(df_test), columns= new_column)\n",
    "\n",
    "\n",
    "X_train.drop('Survived', axis = 1 , inplace = True )\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train['Age'] = min_max_scaler.fit_transform(X_train['Age'].values.reshape(-1,1))\n",
    "X_test['Age'] = min_max_scaler.fit_transform(X_test['Age'].values.reshape(-1,1))\n",
    "\n",
    "X_train['Fare'] = min_max_scaler.fit_transform(X_train['Fare'].values.reshape(-1,1))\n",
    "X_test['Fare'] = min_max_scaler.fit_transform(X_test['Fare'].values.reshape(-1,1))\n",
    "\n",
    "X_train['Sex'] = min_max_scaler.fit_transform(X_train['Sex'].values.reshape(-1,1))\n",
    "X_test['Sex'] = min_max_scaler.fit_transform(X_test['Sex'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "X_train['Pclass'] = min_max_scaler.fit_transform(X_train['Pclass'].values.reshape(-1,1))\n",
    "X_test['Pclass'] = min_max_scaler.fit_transform(X_test['Pclass'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "X_train['Embarked'] = min_max_scaler.fit_transform(X_train['Embarked'].values.reshape(-1,1))\n",
    "X_test['Embarked'] = min_max_scaler.fit_transform(X_test['Embarked'].values.reshape(-1,1))\n",
    "\n",
    "X_train['Family'] = min_max_scaler.fit_transform(X_train['Family'].values.reshape(-1,1))\n",
    "X_test['Family'] = min_max_scaler.fit_transform(X_test['Family'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_tr, X_te, Y_tr, Y_te = train_test_split(X_train, Y_train, test_size=0.33, random_state=42) \n",
    "\n",
    "# The following parameters are computed by GridSearchCV\n",
    "\n",
    "classifiers = []\n",
    "model1 = xgboost.XGBClassifier(eval_metric='mlogloss')\n",
    "classifiers.append(model1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model2 = svm.SVC(C = 5)\n",
    "classifiers.append(model2)\n",
    "\n",
    "\n",
    "model3 = tree.DecisionTreeClassifier(criterion= 'entropy', splitter='best')\n",
    "classifiers.append(model3)\n",
    "\n",
    "\n",
    "model4 = RandomForestClassifier(criterion='entropy')\n",
    "classifiers.append(model4)\n",
    "\n",
    "model5 = LogisticRegression()\n",
    "classifiers.append(model5)\n",
    "\n",
    "model6 =KNeighborsClassifier(n_neighbors = 4)\n",
    "classifiers.append(model6)\n",
    "\n",
    "\n",
    "model7 = GaussianNB()\n",
    "classifiers.append(model7)\n",
    "\n",
    "\n",
    "model8 = Perceptron()\n",
    "classifiers.append(model8)\n",
    "\n",
    "\n",
    "model9 = LinearSVC()\n",
    "classifiers.append(model9)\n",
    "\n",
    "model10 = SGDClassifier()\n",
    "classifiers.append(model10)\n",
    "\n",
    "#ModelName = [type(classifiers[i]).__name__ for i in range(0,10)]\n",
    "#cross_val_score(clf, X_train, Y_train, cv=kfold).mean()*100.0\n",
    "\n",
    "Model_Score = []\n",
    "for clf in classifiers:\n",
    "    kfold = KFold(n_splits=10, random_state= 0, shuffle= True)\n",
    "    #clf.fit(X_tr, Y_tr)\n",
    "    #Y_pred= clf.predict(X_te)\n",
    "    Model_Score.append(cross_val_score(clf, X_train, Y_train, cv=kfold).mean()*100.0)\n",
    "ModelDF = pd.DataFrame({'Model' : ModelName, 'Score' : pd.Series(Model_Score)})\n",
    "ModelDF.sort_values(by = 'Score', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "461046b0-822c-401b-af5a-3b9779cb4f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.00003</td>\n",
       "      <td>1.99990</td>\n",
       "      <td>-0.00100</td>\n",
       "      <td>0.00346</td>\n",
       "      <td>-0.00038</td>\n",
       "      <td>-0.00187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1        2       3        4        5\n",
       "0 -0.00003 1.99990 -0.00100 0.00346 -0.00038 -0.00187"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "clf =SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred= clf.predict(X_test)\n",
    "pd.DataFrame(clf.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1eb69c84-d096-4568-beda-16393aa89400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.27500</td>\n",
       "      <td>0.01367</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.47500</td>\n",
       "      <td>0.13867</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.32500</td>\n",
       "      <td>0.01562</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.10352</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.01562</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.33750</td>\n",
       "      <td>0.02539</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.23750</td>\n",
       "      <td>0.05859</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.04492</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.32500</td>\n",
       "      <td>0.05859</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.01562</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex     Age    Fare  Embarked  Family\n",
       "0   1.00000 0.00000 0.27500 0.01367   1.00000 0.10000\n",
       "1   0.00000 1.00000 0.47500 0.13867   0.00000 0.10000\n",
       "2   1.00000 1.00000 0.32500 0.01562   1.00000 0.00000\n",
       "3   0.00000 1.00000 0.43750 0.10352   1.00000 0.10000\n",
       "4   1.00000 0.00000 0.43750 0.01562   1.00000 0.00000\n",
       "..      ...     ...     ...     ...       ...     ...\n",
       "886 0.50000 0.00000 0.33750 0.02539   1.00000 0.00000\n",
       "887 0.00000 1.00000 0.23750 0.05859   1.00000 0.00000\n",
       "888 1.00000 1.00000 0.37500 0.04492   1.00000 0.30000\n",
       "889 0.00000 0.00000 0.32500 0.05859   0.00000 0.00000\n",
       "890 1.00000 0.00000 0.40000 0.01562   0.50000 0.00000\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "32c34184-6f05-4976-9817-7a395753f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred= clf.predict(X_test)\n",
    "Y_pred\n",
    "Y_pred = Y_pred.astype('int')\n",
    "submit = pd.read_csv('gender_submission.csv')\n",
    "submit['Survived'] = pd.Series(Y_pred)\n",
    "submit.to_csv('KaggleTitanicSubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4d5471c0-d08d-439f-ad96-257b3c97ea38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
       "                               15, 16, 17, 18, 19],\n",
       "                         'degree': [3, 4, 5], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':['linear', 'poly', 'rbf', 'sigmoid'], 'C':[i for i in range(1,20)],'degree':[3,4,5], 'gamma':['scale', 'auto']}\n",
    "clf = GridSearchCV(SVC(), parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5441c254-592e-4f46-979d-86ea767cbd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2d46a6fd-dc98-45dc-8dfb-92f01237a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'dual': False, 'intercept_scaling': 1, 'max_iter': 100}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C':[i for i in range(1,20)],'intercept_scaling':[1,2,3,4], 'max_iter':[100,200,300,400], 'dual':[True, False]}\n",
    "clf = GridSearchCV(LogisticRegression(), parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "clf.best_estimator_\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "addd802c-5477-419e-a28f-002e01990bc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'coefe_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-ed9631119a51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefe_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'coefe_'"
     ]
    }
   ],
   "source": [
    "clf.coefe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bb6708ea-beb8-4d6c-a9e4-b8dbc95f9d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d91099c6-cece-4996-be05-2b75ddae460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(criterion='entropy', splitter='random') {'criterion': 'entropy', 'splitter': 'random'}\n",
      "DecisionTreeClassifier(criterion='entropy') {'criterion': 'entropy', 'splitter': 'best'}\n",
      "DecisionTreeClassifier(criterion='entropy') {'criterion': 'entropy', 'splitter': 'best'}\n",
      "DecisionTreeClassifier(criterion='entropy') {'criterion': 'entropy', 'splitter': 'best'}\n",
      "DecisionTreeClassifier() {'criterion': 'gini', 'splitter': 'best'}\n",
      "DecisionTreeClassifier(criterion='entropy', splitter='random') {'criterion': 'entropy', 'splitter': 'random'}\n",
      "DecisionTreeClassifier(criterion='entropy', splitter='random') {'criterion': 'entropy', 'splitter': 'random'}\n",
      "DecisionTreeClassifier() {'criterion': 'gini', 'splitter': 'best'}\n",
      "DecisionTreeClassifier(criterion='entropy') {'criterion': 'entropy', 'splitter': 'best'}\n",
      "DecisionTreeClassifier(criterion='entropy', splitter='random') {'criterion': 'entropy', 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11): \n",
    "    parameters = {'criterion':['gini', 'entropy'],'splitter' : ['best', 'random']}\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(), parameters)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(clf.best_estimator_ , clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "90cafd1b-152e-4ac7-a978-86aef3f6311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion= 'entropy', splitter='best')\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred= clf.predict(X_test)\n",
    "Y_pred\n",
    "Y_pred = Y_pred.astype('int')\n",
    "submit = pd.read_csv('gender_submission.csv')\n",
    "submit['Survived'] = pd.Series(Y_pred)\n",
    "submit.to_csv('KaggleTitanicSubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7f71c9dd-1fa2-4082-9f09-8c23e6d40f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', n_estimators=400) {'criterion': 'entropy', 'n_estimators': 400}\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=300) {'criterion': 'entropy', 'n_estimators': 300}\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=200) {'criterion': 'entropy', 'n_estimators': 200}\n",
      "RandomForestClassifier(criterion='entropy') {'criterion': 'entropy', 'n_estimators': 100}\n",
      "RandomForestClassifier(n_estimators=300) {'criterion': 'gini', 'n_estimators': 300}\n",
      "RandomForestClassifier() {'criterion': 'gini', 'n_estimators': 100}\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=200) {'criterion': 'entropy', 'n_estimators': 200}\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=300) {'criterion': 'entropy', 'n_estimators': 300}\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=300) {'criterion': 'entropy', 'n_estimators': 300}\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=400) {'criterion': 'entropy', 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11): \n",
    "    parameters = {'n_estimators': [100,200,300,400],'criterion': ['gini', 'entropy']}\n",
    "    clf = GridSearchCV(RandomForestClassifier(), parameters)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(clf.best_estimator_ , clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4935a0a-5642-474b-83ee-e85c9feaf863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
